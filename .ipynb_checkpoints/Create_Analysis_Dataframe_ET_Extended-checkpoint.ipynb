{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7b83da",
   "metadata": {},
   "source": [
    "# Generate ET cell output tables from the proofread table and add putative cell type information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "018581bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pcg_skel\n",
    "import tqdm\n",
    "from meshparty import meshwork\n",
    "from caveclient import CAVEclient\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "client = CAVEclient('minnie65_phase3_v1')\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e25f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "\n",
    "now = client.materialize.get_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05026e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeldir = 'skeletons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d05cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the HVA/VISp line:\n",
    "\n",
    "xz0 = [237415, 26308]\n",
    "xz1 = [286783, 8960]\n",
    "\n",
    "x0 = xz0[0]\n",
    "x1 = xz1[0]\n",
    "z0 = xz0[1]\n",
    "z1 = xz1[1]\n",
    "\n",
    "def soma_in_hva(pt):\n",
    "    ptz = pt[2]\n",
    "    ptx = pt[0]\n",
    "    x_thresh = x1 + (ptz-z1) * (x0-x1) / (z0-z1)\n",
    "    return ptx > x_thresh\n",
    "\n",
    "def classify_soma(pt):\n",
    "    if np.any(np.isnan(pt)):\n",
    "        return np.nan\n",
    "        \n",
    "    if soma_in_hva(pt):\n",
    "        return 'hva'\n",
    "    else:\n",
    "        return 'v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1757cfb9",
   "metadata": {},
   "source": [
    "First we want to get a list of outputs from the L5-ET cells, but restricted to their axon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fcc887",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_table = 'bodor_pt_cells'\n",
    "#client.materialize.version == 688\n",
    "\n",
    "et_df = client.materialize.query_table(et_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0694edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:28, 28.68s/it]"
     ]
    }
   ],
   "source": [
    "# Build the skeletons\n",
    "nrns = {}\n",
    "\n",
    "for _, row in tqdm.tqdm(et_df.iterrows()):\n",
    "\n",
    "    #print(row)\n",
    "    if os.path.exists(f\"{skeldir}/{row['pt_root_id']}.h5\"):\n",
    "        nrns[row[\"pt_root_id\"]] = meshwork.load_meshwork(f\"{skeldir}/{row['pt_root_id']}.h5\")\n",
    "   \n",
    "    else:\n",
    "    \n",
    "        nrns[row[\"pt_root_id\"]] = pcg_skel.coord_space_meshwork(\n",
    "            row[\"pt_root_id\"],\n",
    "            client=client,\n",
    "            root_point=row[\"pt_position\"],\n",
    "            root_point_resolution=[4, 4, 40],\n",
    "            collapse_soma=True,\n",
    "            synapses=\"all\",\n",
    "            synapse_table=client.info.get_datastack_info().get(\"synapse_table\"),\n",
    "            timestamp = now,\n",
    "        )\n",
    "\n",
    "        nrns[row[\"pt_root_id\"]].save_meshwork(f\"{skeldir}/{row['pt_root_id']}.h5\")        \n",
    "        \n",
    "# Get the axons\n",
    "for rid, nrn in nrns.items():\n",
    "    is_axon = meshwork.algorithms.split_axon_by_annotation(\n",
    "        nrn,\n",
    "        'pre_syn',\n",
    "        'post_syn',\n",
    "        return_quality=False\n",
    "    )\n",
    "    nrn.anno.add_annotations('is_axon', is_axon, mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1eb8b",
   "metadata": {},
   "source": [
    "Filter for presynaptic outputs on ET cell axons and concatenate into one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Filter for presynaptic outputs on ET cell axons and concatenate into one dataframe, adding synapse distance:\n",
    "\n",
    "pre_dfs = []\n",
    "for rid in et_df[\"pt_root_id\"]:\n",
    "    syn_filt = nrns[rid].anno.pre_syn.filter_query(\n",
    "            nrns[rid].anno.is_axon.mesh_mask\n",
    "    )\n",
    "    df = syn_filt.df\n",
    "    df['dist_to_root'] = nrns[rid].distance_to_root(syn_filt.mesh_index)\n",
    "    df['distance_rank'] = df['dist_to_root'].rank()\n",
    "    df.attrs = {}\n",
    "    pre_dfs.append(df)\n",
    "\n",
    "et_pre_df= pd.concat(pre_dfs, ignore_index=True)\n",
    "et_pre_df['pre_pt_root_id'] = client.chunkedgraph.get_roots(et_pre_df['pre_pt_supervoxel_id'], timestamp=now)\n",
    "et_pre_df['post_pt_root_id'] = client.chunkedgraph.get_roots(et_pre_df['post_pt_supervoxel_id'], timestamp=now).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c53c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# Get single soma root ids and add cell types\n",
    "\n",
    "soma_df = client.materialize.query_table(\n",
    "    \"nucleus_neuron_svm\", filter_equal_dict={\"cell_type\": \"neuron\"}\n",
    ")\n",
    "\n",
    "\n",
    "# Add number of post_synaptic soma on a segment ID\n",
    "soma_df['count_soma'] = soma_df.groupby('pt_root_id').transform('count')['id']\n",
    "num_soma_df = soma_df.drop_duplicates(subset='pt_root_id')[['pt_root_id', 'count_soma']].rename(\n",
    "    columns={\"count_soma\": \"num_soma\"})\n",
    "num_soma_df = num_soma_df.drop_duplicates(subset=\"pt_root_id\", keep='first')\n",
    "\n",
    "\n",
    "def number_of_soma(row):               \n",
    "    if pd.isna(row['num_soma']) == True:\n",
    "          return 0    \n",
    "    else:\n",
    "          return row['num_soma']  \n",
    "num_soma_df['num_soma'] = num_soma_df.apply(number_of_soma, axis=1)\n",
    "\n",
    "\n",
    "# Remove all duplicates\n",
    "soma_df = soma_df.drop_duplicates(subset=\"pt_root_id\", keep='first')\n",
    "\n",
    "# Download all the other tables we want to pull info from\n",
    "#ei_aibs_df = client.materialize.query_table(\"allen_soma_coarse_cell_class_model_v2\").drop_duplicates('pt_root_id', keep=False)\n",
    "ei_bay_df = client.materialize.query_table(\"baylor_e_i_model_v1\").drop_duplicates('pt_root_id', keep=False)\n",
    "aibs_multi_df = client.materialize.query_table(\n",
    "    \"aibs_soma_nuc_metamodel_preds_v117\",\n",
    "    filter_equal_dict={\"classification_system\": \"aibs_neuronal\"},\n",
    ").drop_duplicates('pt_root_id', keep=False)\n",
    "\n",
    "\n",
    "# Download all the other tables we want to pull info from\n",
    "NEURD_df = client.materialize.query_table(\"baylor_e_i_model_v1\").drop_duplicates('pt_root_id', keep=False)\n",
    "\n",
    "metamodel_df = client.materialize.query_table(\n",
    "    \"aibs_soma_nuc_metamodel_preds_v117\",\n",
    "    filter_equal_dict={\"classification_system\": \"aibs_neuronal\"},\n",
    ").drop_duplicates('pt_root_id', keep=False)\n",
    "\n",
    "mtypes_model_df = client.materialize.query_table(\n",
    "    \"aibs_soma_nuc_exc_mtype_preds_v117\",\n",
    "    filter_equal_dict={\"classification_system\": \"aibs_coarse_excitatory\"},\n",
    ").drop_duplicates('pt_root_id', keep=False)\n",
    "\n",
    "# Enrich soma_df with all this info\n",
    "soma_df = (\n",
    "    soma_df.merge(\n",
    "        NEURD_df[[\"pt_root_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"NEURD_class\"}\n",
    "        ),\n",
    "        on=\"pt_root_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        metamodel_df[[\"pt_root_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"metamodel_cell_type\"}\n",
    "        ),\n",
    "        on=\"pt_root_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        mtypes_model_df[[\"pt_root_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"mtypes_model_cell_type\"}\n",
    "        ),\n",
    "        on=\"pt_root_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63516a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Add nucleus ID to dataframe\n",
    "\n",
    "\n",
    "et_pre_df = (\n",
    "    et_pre_df.merge(\n",
    "        soma_df[[\"id\", \"pt_root_id\"]].rename(\n",
    "            columns={\"id\": \"pre_nucleus_id\"}\n",
    "        ),\n",
    "        left_on=\"pre_pt_root_id\",\n",
    "        right_on=\"pt_root_id\",\n",
    "        how=\"left\",\n",
    "    ).drop(columns=\"pt_root_id\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Add class labels to soma_df\n",
    "def standard_class_metamodel(row):\n",
    "        \n",
    "    if row['metamodel_cell_type'] == 'MC':\n",
    "          return 'inhibitory'\n",
    " \n",
    "    if row['metamodel_cell_type'] == 'BC':\n",
    "          return 'inhibitory'\n",
    "          \n",
    "    if row['metamodel_cell_type'] == 'NGC':\n",
    "          return 'inhibitory'\n",
    "        \n",
    "    if row['metamodel_cell_type'] == 'BPC':\n",
    "          return 'inhibitory'\n",
    "     \n",
    "    if row['metamodel_cell_type'] == 'none':\n",
    "          return None\n",
    "               \n",
    "    if pd.isna(row['metamodel_cell_type']) == True:\n",
    "          return None\n",
    "        \n",
    "    else:\n",
    "          return 'excitatory' \n",
    "\n",
    "soma_df['metamodel_class'] = soma_df.apply(standard_class_metamodel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b67f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Merge all this info from cell types into the synapse dataframe, as well as add area locations.\n",
    "\n",
    "#merge presynaptic nucleous ID\n",
    "synapse_table = et_pre_df.merge(\n",
    "    soma_df[\n",
    "        [\"id\", \"pt_root_id\", \"pt_position\", \"NEURD_class\", \"metamodel_class\", \"metamodel_cell_type\", \"mtypes_model_cell_type\"]\n",
    "    ].rename(columns={\"pt_position\": \"post_soma_pt\"}).rename(columns={\"id\": \"post_nucleus_id\"}),\n",
    "    left_on=\"post_pt_root_id\",\n",
    "    right_on=\"pt_root_id\",\n",
    "    how=\"left\",\n",
    ").drop(columns=\"pt_root_id\")\n",
    "\n",
    "synapse_table[\"post_soma_area\"] = synapse_table['post_soma_pt'].apply(classify_soma)\n",
    "\n",
    "synapse_table = synapse_table.merge(\n",
    "    et_df[['pt_root_id', 'pt_position']].rename(columns={'pt_position': 'pre_soma_pt'}),\n",
    "    left_on='pre_pt_root_id',\n",
    "    right_on='pt_root_id',\n",
    "    how='left',\n",
    ").drop(columns='pt_root_id')\n",
    "\n",
    "synapse_table[\"pre_soma_area\"] = synapse_table['pre_soma_pt'].apply(classify_soma)\n",
    "\n",
    "synapse_table = synapse_table.rename(columns={\"cell_type_pred\": \"aibs_auto_subclass\"})\n",
    "\n",
    "\n",
    "# load manual labels\n",
    "\n",
    "manual_multi_df = client.materialize.live_live_query(\n",
    "    'pt_synapse_targets',\n",
    "    timestamp=\"now\",\n",
    "    metadata=False,\n",
    ")\n",
    "#manual_multi_df = client.materialize.query_table(\"pt_synapse_targets\")\n",
    "manual_multi_df = manual_multi_df.rename(columns={\"target_id\": \"synapse_id\"})\n",
    "#manual_multi_df = client.materialize.query_table(\"pt_synapse_targets\").drop_duplicates('post_pt_root_id', keep=False)\n",
    "#manual_multi_df['post_pt_root_id'] = manual_multi_df.post_pt_root_id.astype('UInt64')\n",
    "\n",
    "\n",
    "#manual_multi_df = pd.read_feather('manual_pt.feather')\n",
    "\n",
    "synapse_table = synapse_table.rename(columns={\"id\": \"synapse_id\"})\n",
    "\n",
    "\n",
    "#merge manual labels\n",
    "\n",
    "synapse_table = (\n",
    "    synapse_table.merge(\n",
    "        manual_multi_df[[\"synapse_id\", \"classification_system\"]].rename(\n",
    "            columns={\"classification_system\": \"manual_class\"}\n",
    "        ),\n",
    "        on='synapse_id',\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        manual_multi_df[[\"synapse_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"manual_subclass\"}\n",
    "        ),\n",
    "        on='synapse_id',\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        num_soma_df[[\"pt_root_id\", \"num_soma\"]],\n",
    "        left_on='post_pt_root_id',\n",
    "        right_on='pt_root_id',\n",
    "        how=\"left\",\n",
    "    ).drop(columns='pt_root_id')\n",
    ")  \n",
    "\n",
    "def number_of_soma(row):               \n",
    "    if pd.isna(row['num_soma']) == True:\n",
    "          return 0    \n",
    "    else:\n",
    "          return row['num_soma']  \n",
    "synapse_table['num_soma'] = synapse_table.apply(number_of_soma, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515956ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# Add alternative nucleous points\n",
    "\n",
    "nucleus_alternative_df = client.materialize.query_table('nucleus_alternative_points')\n",
    "\n",
    "synapse_table = synapse_table.merge(\n",
    "    nucleus_alternative_df[\n",
    "        [\"pt_root_id\", \"id_ref\", \"pt_position\"]\n",
    "    ].rename(columns={\"pt_position\": \"post_soma_pt2\"}),\n",
    "    left_on=\"post_pt_root_id\",\n",
    "    right_on=\"pt_root_id\",\n",
    "    how=\"left\",\n",
    ").drop(columns=\"pt_root_id\")\n",
    "\n",
    "\n",
    "def add_nucleus_ID(row):\n",
    "   \n",
    "    if pd.isna(row['id_ref']) == True:\n",
    "          return row['post_nucleus_id']\n",
    "    \n",
    "    else:\n",
    "          return row['id_ref']  \n",
    "\n",
    "synapse_table['post_nucleus_id'] = synapse_table.apply(add_nucleus_ID, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def add_soma_pt(row):\n",
    "   \n",
    "    if pd.isna(row['id_ref']) == True:\n",
    "          return row['post_soma_pt']\n",
    "    \n",
    "    else:\n",
    "          return row['post_soma_pt2']  \n",
    "\n",
    "synapse_table['post_soma_pt'] = synapse_table.apply(add_soma_pt, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def add_num_soma(row):\n",
    "   \n",
    "    if pd.isna(row['id_ref']) == True:\n",
    "          return row['num_soma']\n",
    "    \n",
    "    else:\n",
    "          if row['num_soma'] > 0:\n",
    "                print(row['num_soma'])\n",
    "                print('ID:', row['id_ref'], ' has ', row['num_soma'], ' somata' )\n",
    "                return row['num_soma']\n",
    "        \n",
    "          else:\n",
    "                return 1  \n",
    "\n",
    "synapse_table['num_soma'] = synapse_table.apply(add_num_soma, axis=1)\n",
    "\n",
    "synapse_table = synapse_table.drop(['id_ref', 'post_soma_pt2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66654948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize class labels\n",
    "def standard_class_NEURD(row):\n",
    "        \n",
    "    if pd.isna(row['NEURD_class']) == True:\n",
    "          return None\n",
    "    else:\n",
    "          return row['NEURD_class']  \n",
    "\n",
    "synapse_table['NEURD_class'] = synapse_table.apply(standard_class_NEURD, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e00e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize sub_class labels\n",
    "def standard_subclass_metamodel(row):\n",
    "        \n",
    "    if row['metamodel_cell_type'] == '6P-IT':\n",
    "          return '6P'\n",
    "\n",
    "    if row['metamodel_cell_type'] == '6P-CT':\n",
    "          return '6P'\n",
    "    \n",
    "    if pd.isna(row['metamodel_cell_type']) == True:\n",
    "          return None\n",
    "    \n",
    "    else:\n",
    "          return row['metamodel_cell_type']  \n",
    "\n",
    "synapse_table['metamodel_cell_type'] = synapse_table.apply(standard_subclass_metamodel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff20e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize sub_class labels\n",
    "def standard_subclass_mytpes_model(row):\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L3c':\n",
    "          return '23P'\n",
    "    \n",
    "    if row['mtypes_model_cell_type'] == 'L5ET':\n",
    "          return '5P-PT'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L2b':\n",
    "          return '23P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L6a':\n",
    "          return '6P'\n",
    "  \n",
    "    if row['mtypes_model_cell_type'] == 'L4c':\n",
    "          return '4P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L6c':\n",
    "          return '6P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L6CT':\n",
    "          return '6P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L6b':\n",
    "          return '6P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L4a':\n",
    "          return '4P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L2a':\n",
    "          return '23P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L3b':\n",
    "          return '23P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L3a':\n",
    "          return '23P'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L5b':\n",
    "          return '5P-IT'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L4b':\n",
    "          return '4P'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L5a':\n",
    "          return '5P-IT'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L5NP':\n",
    "          return '5P-NP'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L6wm':\n",
    "          return '6P'\n",
    "\n",
    "    if pd.isna(row['mtypes_model_cell_type']) == True:\n",
    "          return None\n",
    "    else:\n",
    "          return row['mtypes_model_cell_type']  \n",
    "\n",
    "synapse_table['mtypes_model_cell_type'] = synapse_table.apply(standard_subclass_mytpes_model, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a82d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize class labels from manual\n",
    "def standard_class_man(row):\n",
    "        \n",
    "    if row['manual_class'] == 'none':\n",
    "          return None        \n",
    "\n",
    "    if pd.isna(row['manual_class']) == True:\n",
    "          return None\n",
    "         \n",
    "    else:\n",
    "          return row['manual_class']  \n",
    "\n",
    "synapse_table['manual_class'] = synapse_table.apply(standard_class_man, axis=1)\n",
    "\n",
    "synapse_table = synapse_table[(synapse_table['manual_class'] != 'error')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef05eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize sub_class labels\n",
    "def standard_subclass_man(row):\n",
    "        \n",
    "    if row['manual_subclass'] == 'multisoma':\n",
    "          return None\n",
    "\n",
    "    if row['manual_subclass'] == 'DTC':\n",
    "          return 'MC'               \n",
    "               \n",
    "    if row['manual_subclass'] == 'none':\n",
    "          return None\n",
    "\n",
    "    if row['manual_subclass'] == '5P-PT':\n",
    "          return '5P-ET'\n",
    "        \n",
    "    if row['manual_subclass'] == 'unclear':\n",
    "          return None\n",
    "    \n",
    "    if pd.isna(row['manual_subclass']) == True:\n",
    "          return None\n",
    "    else:\n",
    "          return row['manual_subclass']  \n",
    "\n",
    "synapse_table['manual_subclass'] = synapse_table.apply(standard_subclass_man, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19492b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#QC - CHECK IF THERE ARE DFERRENT MANUAL CLASS LABELS ASIGNED TO THE SAME NEURON \n",
    "\n",
    "for ii in synapse_table.post_pt_root_id.unique():\n",
    "\n",
    "    if len(synapse_table[(synapse_table['post_pt_root_id'] == ii) &\n",
    "                    pd.notna(synapse_table['manual_class'])].manual_class.unique()) > 1:\n",
    "    #if len(synapse_table[(synapse_table['post_pt_root_id'] == ii) & (synapse_table['num_soma'] < 2) &\n",
    "    #                pd.notna(synapse_table['manual_class'])].manual_class.unique()) > 1:\n",
    "        print(ii)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65412c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#QC - CHECK IF THERE ARE DFERRENT MANUAL SUBCLASS LABELS ASIGNED TO THE SAME NEURON \n",
    "\n",
    "for ii in synapse_table.post_pt_root_id.unique():\n",
    "\n",
    "    if len(synapse_table[(synapse_table['post_pt_root_id'] == ii) & (synapse_table['num_soma'] < 2) \n",
    "                         & pd.notna(synapse_table['manual_subclass'])].manual_subclass.unique()) > 1:\n",
    "        print(ii)\n",
    "        \n",
    "    if len(synapse_table[(synapse_table['post_pt_root_id'] == ii) & (synapse_table['num_soma'] < 2) \n",
    "                         & pd.notna(synapse_table['manual_subclass'])].manual_subclass.unique()) > 1:\n",
    "\n",
    "        print(ii) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#TRANSFER MANUAL SUBCLASS LABELS ACROSS SYNAPSES OF THE SAME NEURON\n",
    "\n",
    "#Create df with subclass labels and only one post_pt_root_id for IDs that are single somas or orphans\n",
    "manual_subclass_labels = synapse_table[(synapse_table['num_soma'] <= 1) &\n",
    "                                      pd.notna(synapse_table['manual_subclass'])].drop_duplicates(subset='post_pt_root_id')\n",
    "\n",
    "manual_subclass_labels = manual_subclass_labels[['post_pt_root_id', 'manual_subclass']] \n",
    "\n",
    "#Transfer the subclass labels using the merge function \n",
    "#(In an earlier version I created a new table after this point \"#synapse_table_transfer\")\n",
    "\n",
    "synapse_table = synapse_table.merge(manual_subclass_labels, left_on='post_pt_root_id',\n",
    "                                                      right_on='post_pt_root_id', how='left')\n",
    "\n",
    "#Transfer the subclass labels on multisoma\n",
    "def subclass_transfer(row):\n",
    "   \n",
    "    if pd.isna(row['manual_subclass_y']) == True:\n",
    "          return row['manual_subclass_x']\n",
    "   \n",
    "    else:\n",
    "          return row['manual_subclass_y']  \n",
    "\n",
    "synapse_table['manual_subclass_y'] = synapse_table.apply(subclass_transfer, axis=1)\n",
    "\n",
    "#Rename columns\n",
    "synapse_table = synapse_table.rename(columns={\"manual_subclass_x\": \"manual_subclass_original\",\n",
    "                                                                \"manual_subclass_y\": \"manual_subclass\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#TRANSFER Manual CLASS LABELS ACROSS SYNAPSES OF THE SAME NEURON\n",
    "\n",
    "#Create df with subclass labels and only one post_pt_root_id for IDs that are single somas or orphans\n",
    "manual_class_labels = synapse_table[(synapse_table['num_soma'] <= 1) &\n",
    "                                      pd.notna(synapse_table['manual_class'])].drop_duplicates(subset='post_pt_root_id')\n",
    "\n",
    "manual_class_labels = manual_class_labels[['post_pt_root_id', 'manual_class']] \n",
    "\n",
    "#Transfer the subclass labels using the merge function\n",
    "synapse_table = synapse_table.merge(manual_class_labels, left_on='post_pt_root_id',\n",
    "                                                      right_on='post_pt_root_id', how='left')\n",
    "\n",
    "#Transfer multisoma labels\n",
    "def class_transfer(row):\n",
    "   \n",
    "    if pd.isna(row['manual_class_y']) == True:\n",
    "          return row['manual_class_x']\n",
    "   \n",
    "    else:\n",
    "          return row['manual_class_y']  \n",
    "\n",
    "synapse_table['manual_class_y'] = synapse_table.apply(class_transfer, axis=1)\n",
    "\n",
    "#Rename columns\n",
    "synapse_table = synapse_table.rename(columns={\"manual_class_x\": \"manual_class_original\",\n",
    "                                              \"manual_class_y\": \"manual_class\"})\n",
    "\n",
    "#bool_mask = synapse_table_transfer['manual_class_y'].isna()\n",
    "#synapse_table_transfer[bool_mask]['manual_class_y'] = synapse_table_transfer[bool_mask]['manual_class_x'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#QC - CHECK IF THE MANUAL CLASS AND SUBCLASS ARE CONSISTENT\n",
    "\n",
    "#create new column where class is calculated from subclass\n",
    "def create_class_from_subclass(row):\n",
    "    if row['manual_subclass'] == '5P-NP':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '5P-ET':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '5P-IT':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '4P':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '6P':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '23P':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == 'BC':\n",
    "          return 'inhibitory'\n",
    "    if row['manual_subclass'] == 'MC':\n",
    "          return 'inhibitory'\n",
    "    if row['manual_subclass'] == 'BPC':\n",
    "          return 'inhibitory'\n",
    "    else:\n",
    "          return row['manual_subclass']\n",
    "\n",
    "synapse_table['class_from_subclass'] = synapse_table.apply(create_class_from_subclass, axis=1)\n",
    "\n",
    "\n",
    "def check_class_from_subclass(row):\n",
    "   \n",
    "    if row['manual_class'] == row['class_from_subclass']:\n",
    "          return 'OK'\n",
    "   \n",
    "    else:\n",
    "          return row['manual_subclass']  \n",
    "\n",
    "synapse_table['check_class_from_subclass'] = synapse_table.apply(check_class_from_subclass, axis=1)\n",
    "\n",
    "synapse_table.check_class_from_subclass.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#QC - CHECK DISAGREEMENT BETWEEN Baylor and AIBS LABELS\n",
    "\n",
    "manual_check1 = synapse_table[(synapse_table['NEURD_class'] == 'excitatory') \n",
    "              & (synapse_table['metamodel_class'] == 'inhibitory') & pd.isna(synapse_table['manual_class'])].drop_duplicates(subset='post_pt_root_id')#.post_pt_root_id.unique()\n",
    "\n",
    "print('number of unchecked disagreements where NEURD is \"E\" and metamodel is \"I\": ', len(manual_check1))\n",
    "\n",
    "\n",
    "manual_check2 = synapse_table[(synapse_table['NEURD_class'] == 'inhibitory') \n",
    "              & (synapse_table['metamodel_class'] == 'excitatory') & pd.isna(synapse_table['manual_class'])].drop_duplicates(subset='post_pt_root_id')#.post_pt_root_id.unique()\n",
    "\n",
    "print('number of unchecked disagreements where NEURD is \"I\" and metamodel is \"E\": ', len(manual_check2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32017b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#QC - CHECK FOR LABELS WITH NO ENTRIES\n",
    "\n",
    "manual_check = synapse_table[pd.isna(synapse_table['NEURD_class']) \n",
    "              & pd.isna(synapse_table['metamodel_class']) & pd.isna(synapse_table['manual_class'])].drop_duplicates(subset='post_pt_root_id')#.post_pt_root_id.unique()\n",
    "\n",
    "manual_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32881844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#INTEGRATE CLASS LABELS BETWEEN MANUAL AND AUTOMATED LABELS\n",
    "\n",
    "#generate new consensus column\n",
    "synapse_table['consensus_class'] = synapse_table['manual_class']\n",
    "\n",
    "#When there isn't manual label add aibs_v2 label\n",
    "\n",
    "def integrate_class(row):\n",
    "    if row['consensus_class'] == None:\n",
    "          return row['metamodel_class']\n",
    "    \n",
    "    else:\n",
    "          return row['consensus_class']  \n",
    "\n",
    "synapse_table['consensus_class'] = synapse_table.apply(integrate_class, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19096558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#INTEGRATE SUBCLASS LABELS BETWEEN MANUAL AND AUTOMATED LABELS\n",
    "\n",
    "#generate new consensus column\n",
    "synapse_table['consensus_subclass'] = synapse_table['manual_subclass']\n",
    "\n",
    "#When there isn't manual label add aibs_v2 label\n",
    "\n",
    "def integrate_subclass(row):\n",
    "    if row['consensus_subclass'] == None:\n",
    "          return row['metamodel_cell_type']\n",
    "    if row['consensus_subclass'] == 'inhibitory':\n",
    "          return None      \n",
    "    \n",
    "    else:\n",
    "          return row['consensus_subclass']  \n",
    "\n",
    "synapse_table['consensus_subclass'] = synapse_table.apply(integrate_subclass, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#QC - CHECK IF THE INTEGRATED CLASS AND SUBCLASS ARE CONSISTENT\n",
    "\n",
    "#remove previous columns\n",
    "synapse_table = synapse_table.drop(['class_from_subclass', 'check_class_from_subclass'], axis=1)\n",
    "#synapse_table = synapse_table.drop(['class_from_subclass'], axis=1)\n",
    "\n",
    "\n",
    "#create new column where class is calculated from subclass\n",
    "def create_class_from_subclass(row):\n",
    "    if row['consensus_subclass'] == '5P-NP':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '5P-ET':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '5P-IT':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '4P':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '6P':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '6P-IT':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '6P-CT':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '23P':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == 'BC':\n",
    "          return 'inhibitory'\n",
    "    if row['consensus_subclass'] == 'MC':\n",
    "          return 'inhibitory'\n",
    "    if row['consensus_subclass'] == 'NGC':\n",
    "          return 'inhibitory'\n",
    "    if row['consensus_subclass'] == 'BPC':\n",
    "          return 'inhibitory'\n",
    "    if row['consensus_subclass'] == 'inhibitory':\n",
    "          return 'unknown'        \n",
    "        \n",
    "    else:\n",
    "          return row['consensus_subclass']\n",
    "\n",
    "synapse_table['class_from_subclass'] = synapse_table.apply(create_class_from_subclass, axis=1)\n",
    "\n",
    "\n",
    "def check_class_from_subclass(row):\n",
    "   \n",
    "    if row['consensus_class'] == row['class_from_subclass']:\n",
    "          return 'OK'\n",
    "   \n",
    "    else:\n",
    "          return row['consensus_subclass']  \n",
    "\n",
    "synapse_table['check_class_from_subclass'] = synapse_table.apply(check_class_from_subclass, axis=1)\n",
    "\n",
    "synapse_table.check_class_from_subclass.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#SAVE AND READ\n",
    "\n",
    "#remove columns before saving\n",
    "synapse_table = synapse_table.drop(['class_from_subclass', 'check_class_from_subclass'], axis=1)\n",
    "\n",
    "\n",
    "#save et_pre_ct_df\n",
    "synapse_table.reset_index(drop=True).to_feather(\"ET_extended_synapse_table.feather\")\n",
    "\n",
    "#READ\n",
    "#et_pre_ct_df = pd.read_feather('ET_Column_syn_df_NC.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486666fd",
   "metadata": {},
   "source": [
    "# EXTRAS TO BE DELETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a098c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_check = synapse_table[(synapse_table['post_pt_root_id'] == 864691136953075423)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae630546",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdca3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NEUROGLANCER LINK\n",
    "\n",
    "\n",
    "manual_check = synapse_table[(synapse_table['synapse_id']== 138873793)].drop_duplicates(subset='post_pt_root_id')\n",
    "#manual_check = synapse_table[(synapse_table['manual_eiaibs_subclass']== '5P-PT') & (synapse_table['pre_pt_root_id']==864691135293076662)].drop_duplicates(subset='post_pt_root_id')\n",
    "#manual_check = manual_check.drop_duplicates(subset='post_pt_root_id')\n",
    "\n",
    "\n",
    "from nglui import statebuilder\n",
    "\n",
    "img, seg = statebuilder.from_client(client)\n",
    "\n",
    "pt_map = statebuilder.PointMapper('post_pt_position', linked_segmentation_column='post_pt_root_id')\n",
    "anno = statebuilder.AnnotationLayerConfig('post_pt_position', mapping_rules=pt_map, linked_segmentation_layer=seg.name,\n",
    "                                          tags=['single_spine','dendrite', 'error', 'has_soma'])\n",
    "sb = statebuilder.StateBuilder([img, seg, anno], client=client)\n",
    "\n",
    "#here is where you add the dataframe\n",
    "sb.render_state(manual_check[['post_pt_root_id','post_pt_position']], return_as='html')\n",
    "\n",
    "#[id, x,y,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32dac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9138df",
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_table[['synapse_id','pre_nucleus_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f599e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_table_1.num_soma.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1915731",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_nucleus_ID_df = synapse_table[(synapse_table['post_pt_root_id'] == 864691136418722199)]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f170b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_nucleus_ID_df.post_nucleus_id.astype('int').unique().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfe561",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_nucleus_ID_df.consensus_class.unique().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKE STATS DATAFRAME - All synapses and connections\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "#Load dataframe\n",
    "synapse_table = pd.read_feather(\"ET_extended_synapse_table.feather\")\n",
    "synapse_table = synapse_table[synapse_table['num_soma'] == 1]\n",
    "\n",
    "\n",
    "#get ET neurons root IDs\n",
    "post_soma_IDs = synapse_table.post_pt_root_id.unique()\n",
    "print('number of connections: ',len(All_neurons))\n",
    "\n",
    "#'y' location of cortical surface\n",
    "surface_y_column =[84534, 85689, 86053, 87800, 89421, 90105, 82884, 81677, 86242]\n",
    "average_surface_location = mean(surface_y_column)\n",
    "\n",
    "\n",
    "#Create Dataframe\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "values = []\n",
    "\n",
    "for ii,post_soma_ID in enumerate(pre_soma_IDs):        \n",
    "        \n",
    "    post_nucleus_ID_df = synapse_table[(synapse_table['post_pt_root_id'] == post_soma_ID)],\n",
    "                    \n",
    "    \n",
    "    stat_values={\n",
    "\n",
    "                    'ID': post_soma_ID,\n",
    "                    'nucleus_ID':  post_nucleus_ID_df.post_nucleus_id.astype('int').unique().item(),\n",
    "                    \n",
    "    #SYNAPSES\n",
    "                    \n",
    "                    'syn_total': len(post_nucleus_ID_df),\n",
    "                    'class': post_nucleus_ID_df.consensus_class.unique().item(),\n",
    "                    'subclass': post_nucleus_ID_df.consensus_subclass.unique().item(),\n",
    "                        \n",
    "        \n",
    "    }\n",
    "    values.append(stat_values)\n",
    "\n",
    "synapse_table_values = pd.DataFrame(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda44a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_pre_ct_df.manual_subclass.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e70ed",
   "metadata": {},
   "source": [
    "`pt_pre_ct_df` is now a complete list of axonal presynaptic synapses of all the ET cells.\n",
    "\n",
    "Now let's look at the downstream proofread cells in table `bodor_pt_target_proofread`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35def871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pt_pre_ct_df\n",
    "et_pre_ct_df.reset_index(drop=True).to_feather(\"ET_ccomplete_syn_df_NC_20230505b.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_multi_df.reset_index(drop=True).to_feather(\"manual_pt.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2732f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = client.materialize.query_table('bodor_pt_target_proofread')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_df = target_df.query('cell_type == \"MC\"')\n",
    "bc_df = target_df.query('cell_type == \"BC\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d79ad",
   "metadata": {},
   "source": [
    "Now let's go down the BC targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_output_df = client.materialize.synapse_query(pre_ids=bc_df['pt_root_id'])\n",
    "\n",
    "bc_output_df = (\n",
    "    bc_output_df.merge(\n",
    "        soma_df[\n",
    "        [\"id\",\"pt_root_id\", \"pt_position\", \"ei_aibs\", \"ei_baylor\", \"cell_type_pred\"]\n",
    "        ].rename(columns={\"pt_position\": \"target_soma_pt\"}).rename(columns={\"id\": \"post_nucleus_id\"}),\n",
    "        left_on='post_pt_root_id',\n",
    "        right_on='pt_root_id',\n",
    "        how=\"left\",\n",
    "    ).drop(columns=\"pt_root_id\")\n",
    "    .merge(\n",
    "        soma_df[\n",
    "        [\"id\",\"pt_root_id\"]].rename(columns={\"id\": \"pre_nucleus_id\"}),\n",
    "        left_on='pre_pt_root_id',\n",
    "        right_on='pt_root_id',\n",
    "        how=\"left\",\n",
    "    ).drop(columns=\"pt_root_id\")\n",
    "    .merge(\n",
    "        num_soma_df[[\"pt_root_id\", \"num_soma\"]],\n",
    "        left_on='post_pt_root_id',\n",
    "        right_on='pt_root_id',\n",
    "        how=\"left\",\n",
    "    ).drop(columns='pt_root_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4148c6d",
   "metadata": {},
   "source": [
    "Now let's add a column about number of synapses from proofread ET cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_from_et = pt_pre_ct_df.groupby('post_pt_root_id').count()[['id']].rename(columns={'id': 'syn_from_et'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f01161",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_output_df = bc_output_df.merge(\n",
    "    syn_from_et,\n",
    "    left_on='post_pt_root_id',\n",
    "    right_index=True,\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "bc_output_df['syn_from_et'] = bc_output_df['syn_from_et'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bc_output_df[(bc_output_df['syn_from_et'] > 1)].drop_duplicates(subset=\"post_pt_root_id\", keep='first'))/len(bc_output_df.drop_duplicates(subset=\"post_pt_root_id\", keep='first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_soma_nucs=mc_output_df.query('num_soma == 1').nucleus_id.unique()\n",
    "len(single_soma_nucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79365901",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nuc_ids=mc_output_df.nucleus_id.unique()\n",
    "len(all_nuc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7087cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nuc_ids[~np.isin(all_nuc_ids, single_soma_nucs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bc_output_df.query('num_soma == 0').nucleus_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758af2d",
   "metadata": {},
   "source": [
    "And the MC targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_output_df = client.materialize.synapse_query(pre_ids=mc_df['pt_root_id'])\n",
    "\n",
    "mc_output_df = (\n",
    "    mc_output_df.merge(\n",
    "        soma_df[\n",
    "        [\"id\",\"pt_root_id\", \"pt_position\", \"ei_aibs\", \"ei_baylor\", \"cell_type_pred\"]\n",
    "        ].rename(columns={\"pt_position\": \"target_soma_pt\"}).rename(columns={\"id\": \"post_nucleus_id\"}),\n",
    "        left_on='post_pt_root_id',\n",
    "        right_on='pt_root_id',\n",
    "        how=\"left\",\n",
    "    ).drop(columns=\"pt_root_id\")\n",
    "    .merge(\n",
    "        soma_df[\n",
    "        [\"id\",\"pt_root_id\"]].rename(columns={\"id\": \"pre_nucleus_id\"}),\n",
    "        left_on='pre_pt_root_id',\n",
    "        right_on='pt_root_id',\n",
    "        how=\"left\",\n",
    "    ).drop(columns=\"pt_root_id\")\n",
    "    .merge(\n",
    "        num_soma_df[[\"pt_root_id\", \"num_soma\"]],\n",
    "        left_on='post_pt_root_id',\n",
    "        right_on='pt_root_id',\n",
    "        how=\"left\",\n",
    "    ).drop(columns='pt_root_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19869114",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_output_df = mc_output_df.merge(\n",
    "    syn_from_et,\n",
    "    left_on='post_pt_root_id',\n",
    "    right_index=True,\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "mc_output_df['syn_from_et'] = mc_output_df['syn_from_et'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06756c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mc_output_df[(mc_output_df['syn_from_et'] > 1)].drop_duplicates(subset=\"post_pt_root_id\", keep='first'))/len(mc_output_df.drop_duplicates(subset=\"post_pt_root_id\", keep='first'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246cd3bc",
   "metadata": {},
   "source": [
    "Let's just glimpse at the resulting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9032a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_output_df.drop_duplicates(subset=\"post_pt_root_id\", keep='first').query('syn_from_et > 5 and target_soma_pt.str[1] > 165000').groupby('cell_type_pred').count()[['valid']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ead93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_output_df.drop_duplicates(subset=\"post_pt_root_id\", keep='first').query('target_soma_pt.str[1] > 165000').groupby('cell_type_pred').count()[['valid']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f309dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_output_df.query('syn_from_et > 0 and ei_baylor == \"inhibitory\" and cell_type_pred == \"MC\"')['post_pt_root_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e71e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save bc_output_df\n",
    "bc_output_df.reset_index(drop=True).to_feather(\"BC_syn_df_NC_9Sep.feather\")\n",
    "\n",
    "#save MC_output_df\n",
    "mc_output_df.reset_index(drop=True).to_feather(\"MC_syn_df_NC_9Sep.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_output_df.query('syn_from_et > 0').groupby('cell_type_pred').count()[['valid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff94fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_output_df.drop_duplicates(subset=\"post_pt_root_id\", keep='first').query('syn_from_et > 10 and target_soma_pt.str[1] > 165000').groupby('cell_type_pred').count()[['valid']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_output_df.drop_duplicates(subset=\"post_pt_root_id\", keep='first').query('target_soma_pt.str[1] > 165000').groupby('cell_type_pred').count()[['valid']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_output_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_pre_ct_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0990fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_targets = mc_output_df.query('syn_from_et > 0 and ei_aibs == \"inhibitory\"  and cell_type_pred == \"BC\" and target_soma_pt.str[1] > 165000').drop_duplicates(subset=\"post_pt_root_id\", keep='first')\n",
    "bc_output_df.query('post_pt_root_id == 864691136618564493')\n",
    "#864691136266742772\n",
    "#common_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b373c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NEUROGLANCER LINK\n",
    "\n",
    "from nglui import statebuilder\n",
    "\n",
    "img, seg = statebuilder.from_client(client)\n",
    "\n",
    "pt_map = statebuilder.PointMapper('target_soma_pt', linked_segmentation_column='post_pt_root_id')\n",
    "anno = statebuilder.AnnotationLayerConfig('soma_pts', mapping_rules=pt_map, linked_segmentation_layer=seg.name,\n",
    "                                          tags=['', 'BC'])\n",
    "sb = statebuilder.StateBuilder([img, seg, anno], client=client)\n",
    "\n",
    "\n",
    "sb.render_state(common_targets[['post_pt_root_id','target_soma_pt']], return_as='html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma2_df = client.materialize.query_table(\n",
    "    \"nucleus_neuron_svm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496307a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_MC_df = test_MC_df.merge(\n",
    "    soma2_df,\n",
    "    left_on='post_pt_root_id',\n",
    "    right_on = 'pt_root_id',\n",
    "    how='left',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15beb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#select single soma inhibitory targets\n",
    "MC_i_targets_df = mc_output_df[['nucleus_id','ei_aibs', 'num_soma']].query('ei_aibs == \"inhibitory\"  and num_soma == 1')\n",
    "BC_i_targets_df = bc_output_df[['nucleus_id','ei_aibs', 'num_soma']].query('ei_aibs == \"inhibitory\"  and num_soma == 1')\n",
    "PT_i_targets_df = pt_pre_ct_df[['nucleus_id','ei_aibs', 'num_soma']].query('ei_aibs == \"inhibitory\"  and num_soma == 1')\n",
    "\n",
    "#concatonate inhibitory targets of MC, BC and PTs\n",
    "somaIDs_df = pd.concat([MC_i_targets_df,BC_i_targets_df])\n",
    "somaIDs_df = pd.concat([somaIDs_df,PT_i_targets_df])\n",
    "somaIDs_df = somaIDs_df.drop_duplicates(subset=\"nucleus_id\", keep='first')\n",
    "\n",
    "#save result\n",
    "somaIDs_df.reset_index(drop=True).to_feather(\"inhibitory_targets_Nuno.feather\")\n",
    "\n",
    "somaIDs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "somaIDs_df.query('nucleus_id == 303172')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_MC_df['post_pt_root_id'] = test_MC_df.post_pt_root_id.astype('UInt64')\n",
    "test_MC_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41de317",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_MC_df.query('cell_type == \"neuron\"').id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa42192",
   "metadata": {},
   "outputs": [],
   "source": [
    "somaIDs_df = pd.concat([test_MC_df,test_BC_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff438c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "somaIDs_df = somaIDs_df.drop_duplicates(subset=\"id\", keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e863ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(somaIDs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0110693",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = somaIDs_df.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0142f",
   "metadata": {},
   "source": [
    "# Brendan data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cad924",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brendan_synapses = pd.read_csv('Nuno_downstream_targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a269cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brendan_synapses = Brendan_synapses.merge(\n",
    "    soma_df[\n",
    "    [\"id\", \"ei_aibs\", \"ei_baylor\", \"cell_type_pred\"]\n",
    "    ],\n",
    "    left_on=\"postsyn_nucleus_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\",\n",
    ").drop(columns=\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If syn_from_et was not generated before\n",
    "syn_from_et = syn_from_et.merge(\n",
    "    soma_df[\n",
    "    [\"id\", \"pt_root_id\" ]].rename(columns={\"id\": \"nucleus_id\"}),\n",
    "    left_on=\"post_pt_root_id\",\n",
    "    right_on=\"pt_root_id\",\n",
    "    how=\"left\",\n",
    "    )\n",
    "#.drop(columns=\"pt_root_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with number of synapses from PT\n",
    "Brendan_synapses = Brendan_synapses.merge(\n",
    "    syn_from_et[\n",
    "    [\"nucleus_id\", \"syn_from_et\"]\n",
    "    ],\n",
    "    left_on=\"presyn_nucleus_id\",\n",
    "    right_on=\"nucleus_id\",\n",
    "    how=\"left\",\n",
    ").drop(columns=\"nucleus_id\")\n",
    "\n",
    "Brendan_synapses['syn_from_et'] = Brendan_synapses['syn_from_et'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7051461",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brendan_synapses.syn_from_et.unique()\n",
    "#Brendan_synapses\n",
    "#syn_from_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d295f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get basket cells post synaptic to PT neurons and cleanned by Brendan\n",
    "\n",
    "BC_clean = np.intersect1d(Brendan_synapses.query('syn_from_et > 1').presyn_nucleus_id.unique(), \n",
    "                          pt_pre_ct_df.query('aibs_auto_subclass == \"BC\"').post_nucleus_id.unique())\n",
    "\n",
    "BC_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Brendan_synapses.syn_from_et.unique()\n",
    "#Brendan_synapses.query('presyn_nucleus_id == 232945')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ef2b3",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53206342",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_output_df.query('pre_nucleus_id == 303172').cell_type_pred.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_soma_ID = 303172\n",
    "temp_table = bc_output_df[bc_output_df['pre_nucleus_id'] == pre_soma_ID]\n",
    "temp_table\n",
    "BC_syn = len(temp_table.query('cell_type_pred == \"BC\"'))\n",
    "BC_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_table['cell_type_pred'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdefa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisys total number of synapses (AIBS)\n",
    "\n",
    "stats = []\n",
    "\n",
    "#pre_soma_ID = 340252\n",
    "pre_soma_ID = mc_output_df.pre_nucleus_id.unique()\n",
    "\n",
    "#temp_table = mc_output_df[mc_output_df['pre_nucleus_id'] == pre_soma_ID]\n",
    "\n",
    "\n",
    "for ii in pre_soma_ID:                \n",
    "        \n",
    "    print(ii)\n",
    "    temp_table = mc_output_df[mc_output_df['pre_nucleus_id'] == ii]\n",
    "    #Synapses\n",
    "    total_syn = len(temp_table)\n",
    "\n",
    "    BC_syn = len(temp_table.query('cell_type_pred == \"BC\"'))\n",
    "    MC_syn = len(temp_table.query('cell_type_pred == \"MC\"'))\n",
    "    BPC_syn = len(temp_table.query('cell_type_pred == \"BPC\"'))\n",
    "    NGC_syn = len(temp_table.query('cell_type_pred == \"NGC\"'))\n",
    "\n",
    "    P23_syn = len(temp_table.query('cell_type_pred == \"23P\"'))\n",
    "    P4_syn = len(temp_table.query('cell_type_pred == \"4P\"'))\n",
    "    P5_NP_syn = len(temp_table.query('cell_type_pred == \"5P-NP\"'))\n",
    "    P5_ET_syn = len(temp_table.query('cell_type_pred == \"5P-ET\"'))\n",
    "    P5_IT_syn = len(temp_table.query('cell_type_pred == \"5P-IT\"'))\n",
    "    P6_IT_syn = len(temp_table.query('cell_type_pred == \"6P-IT\"'))\n",
    "    P6_CT_syn = len(temp_table.query('cell_type_pred == \"6P-CT\"'))\n",
    "\n",
    "    unasigned_syn = temp_table['cell_type_pred'].isnull().sum()\n",
    "\n",
    "    total_syn_sum = sum([BC_syn, MC_syn, BPC_syn, NGC_syn,\n",
    "                    P23_syn, P4_syn, P5_NP_syn, P5_ET_syn, P5_IT_syn,\n",
    "                    P6_IT_syn, P6_CT_syn, unasigned_syn])\n",
    "\n",
    "    print(total_syn)\n",
    "    print(total_syn_sum)        \n",
    "\n",
    "\n",
    "    #del temp_table\n",
    "\n",
    "    stat={\n",
    "\n",
    "                    'ID': ii, \n",
    "                    'BC': BC_syn,\n",
    "                    'MC': MC_syn,\n",
    "                    'BPC': BPC_syn,\n",
    "                    'NGC': NGC_syn,\n",
    "\n",
    "                    '23P': P23_syn,\n",
    "                    '4P' : P4_syn,\n",
    "                    '5P-NP':P5_NP_syn,\n",
    "                    '5P-ET':P5_ET_syn,\n",
    "                    '5P-IT':P5_IT_syn,\n",
    "                    '6P-IT':P6_IT_syn,\n",
    "                    '6P-CT':P6_CT_syn,\n",
    "\n",
    "                    'unasigned': unasigned_syn,\n",
    "                    '%5P-ET': P5_ET_syn/(P5_NP_syn+P5_ET_syn+P5_IT_syn),\n",
    "\n",
    "                    }\n",
    "    stats.append(stat)\n",
    "\n",
    "stats_AIBS_MC = pd.DataFrame(stats)\n",
    "\n",
    "\n",
    "#stats_type.append(stat)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a98b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "P5_ET_syn/(P5_NP_syn+P5_ET_syn+P5_IT_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf11e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brendan_synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisys total number of synapses (BCM)\n",
    "\n",
    "cell_typing = 'AIBS'\n",
    "\n",
    "stats = []\n",
    "\n",
    "#pre_soma_ID = [232945]\n",
    "pre_soma_ID = BC_clean\n",
    "#pre_soma_ID = Brendan_synapses.presyn_nucleus_id.unique()\n",
    "\n",
    "for ii in pre_soma_ID:\n",
    "\n",
    "    print(ii)\n",
    "    temp_table = Brendan_synapses[Brendan_synapses['presyn_nucleus_id'] == ii]\n",
    "\n",
    "    #Synapses\n",
    "    total_syn = len(temp_table)\n",
    "\n",
    "    if cell_typing == 'AIBS':\n",
    "\n",
    "        BC_syn = len(temp_table.query('cell_type_pred == \"BC\"'))\n",
    "        MC_syn = len(temp_table.query('cell_type_pred == \"MC\"'))\n",
    "        BPC_syn = len(temp_table.query('cell_type_pred == \"BPC\"'))\n",
    "        NGC_syn = len(temp_table.query('cell_type_pred == \"NGC\"'))\n",
    "\n",
    "        P23_syn = len(temp_table.query('cell_type_pred == \"23P\"'))\n",
    "        P4_syn = len(temp_table.query('cell_type_pred == \"4P\"'))\n",
    "        P5_NP_syn = len(temp_table.query('cell_type_pred == \"5P-NP\"'))\n",
    "        P5_ET_syn = len(temp_table.query('cell_type_pred == \"5P-ET\"'))\n",
    "        P5_IT_syn = len(temp_table.query('cell_type_pred == \"5P-IT\"'))\n",
    "        P6_IT_syn = len(temp_table.query('cell_type_pred == \"6P-IT\"'))\n",
    "        P6_CT_syn = len(temp_table.query('cell_type_pred == \"6P-CT\"'))\n",
    "\n",
    "        unasigned_syn = temp_table['cell_type_pred'].isnull().sum()\n",
    "        \n",
    "\n",
    "    if cell_typing == 'BCM':\n",
    "\n",
    "        BC_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"BC\"'))\n",
    "        MC_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"MC\"'))\n",
    "        BPC_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"BPC\"'))\n",
    "        NGC_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"NGC\"'))\n",
    "\n",
    "        P23_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"23P\"'))\n",
    "        P4_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"4P\"'))\n",
    "        P5_NP_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"5P-NP\"'))\n",
    "        P5_ET_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"5P-PT\"'))\n",
    "        P5_IT_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"5P-IT\"'))\n",
    "        P6_IT_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"6P-IT\"'))\n",
    "        P6_CT_syn = len(temp_table.query('postsyn_gnn_cell_type_fine == \"6P-CT\"'))\n",
    "\n",
    "        unasigned_syn = temp_table['postsyn_gnn_cell_type_fine'].isnull().sum()\n",
    "        \n",
    "    total_syn_L5 = P5_NP_syn+P5_ET_syn+P5_IT_syn\n",
    "    syn_from_et_value = np.int(temp_table.syn_from_et.unique())\n",
    "    \n",
    "    print(total_syn_L5)\n",
    "        \n",
    "    if total_syn_L5 > 0:\n",
    "        percent_5P_ET = P5_ET_syn/(P5_NP_syn+P5_ET_syn+P5_IT_syn)\n",
    "    else:\n",
    "        percent_5P_ET = np.nan\n",
    "\n",
    "\n",
    "\n",
    "    total_syn_sum = sum([BC_syn, MC_syn, BPC_syn, NGC_syn,\n",
    "                    P23_syn, P4_syn, P5_NP_syn, P5_ET_syn, P5_IT_syn,\n",
    "                    P6_IT_syn, P6_CT_syn, unasigned_syn])\n",
    "\n",
    "    print(total_syn)\n",
    "    print(total_syn_sum)        \n",
    "\n",
    "\n",
    "    #del temp_table\n",
    "\n",
    "    stat={\n",
    "\n",
    "                    'ID': ii, \n",
    "                    'BC': BC_syn,\n",
    "                    'MC': MC_syn,\n",
    "                    'BPC': BPC_syn,\n",
    "                    'NGC': NGC_syn,\n",
    "\n",
    "                    'P23': P23_syn,\n",
    "                    'P4' : P4_syn,\n",
    "                    'P5-NP':P5_NP_syn,\n",
    "                    'P5-ET':P5_ET_syn,\n",
    "                    'P5-IT':P5_IT_syn,\n",
    "                    'P6-IT':P6_IT_syn,\n",
    "                    'P6-CT':P6_CT_syn,\n",
    "\n",
    "                    'unasigned': unasigned_syn,\n",
    "                    'percent_5P_ET': percent_5P_ET,\n",
    "                    'P5_total_syn': total_syn_L5,\n",
    "                    'syn_from_et': syn_from_et_value,\n",
    "\n",
    "                    }\n",
    "    stats.append(stat)\n",
    "\n",
    "stats_BCM = pd.DataFrame(stats)\n",
    "\n",
    "\n",
    "#stats_type.append(stat)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414116d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_BCM#.syn_from_et.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff745fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BC_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7047cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_AIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a589f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_output_df.pre_nucleus_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "vals = np.array([stats_AIBS.iloc[idx]['BC'],stats_AIBS.iloc[idx]['MC'],\n",
    "                  stats_AIBS.iloc[idx]['BPC'],stats_AIBS.iloc[idx]['NGC'],\n",
    "                  stats_AIBS.iloc[idx]['23P'],stats_AIBS.iloc[idx]['4P'],\n",
    "                  stats_AIBS.iloc[idx]['5P-NP'],stats_AIBS.iloc[idx]['5P-ET'],\n",
    "                  stats_AIBS.iloc[idx]['5P-IT'],stats_AIBS.iloc[idx]['6P-IT'],\n",
    "                  stats_AIBS.iloc[idx]['6P-CT'],stats_AIBS.iloc[idx]['orphans']])\n",
    "\n",
    "lab = ['BC', 'MC', 'BPC', 'NGC', '23P', '4P', '5P-NP', '5P-ET', '5P-IT','6P-IT','6P-CT','orphans']\n",
    "\n",
    "ax.bar(lab,vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32110d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "idx = 17\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "vals = np.array([stats_BCM.iloc[idx]['BC'],stats_BCM.iloc[idx]['MC'],\n",
    "                  stats_BCM.iloc[idx]['BPC'],stats_BCM.iloc[idx]['NGC'],\n",
    "                  stats_BCM.iloc[idx]['P23'],stats_BCM.iloc[idx]['P4'],\n",
    "                  stats_BCM.iloc[idx]['P5-NP'],stats_BCM.iloc[idx]['P5-ET'],\n",
    "                  stats_BCM.iloc[idx]['P5-IT'],stats_BCM.iloc[idx]['P6-IT'],\n",
    "                  stats_BCM.iloc[idx]['P6-CT'],stats_BCM.iloc[idx]['unasigned']])\n",
    "\n",
    "lab = ['BC', 'MC', 'BPC', 'NGC', '23P', '4P', '5P-NP', '5P-ET', '5P-IT','6P-IT','6P-CT','unasigned']\n",
    "\n",
    "ax.bar(lab,vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_BCM['dummy'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0a771",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Make violin plot\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "#ax.set(xlim=(0, 0.9))\n",
    "\n",
    "ax = sns.swarmplot(data = stats_BCM.query('P5_total_syn > 50'), x='dummy', y=\"percent_5P_ET\", size=8, hue=\"syn_from_et\", palette=\"viridis\")\n",
    "ax.set(ylim=(0, 0.9))\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('swarm.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eeb71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_BCM.query('percent_5P_ET < 0.5 and P5_total_syn > 50 and syn_from_et > 20' ).ID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75fe8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_BCM.query('P5_total_syn > 50').syn_from_et\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Brendan_synapses.presyn_nucleus_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd1a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae918c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_multi_df[manual_multi_df['synapse_id'] == 127538363]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f6555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
