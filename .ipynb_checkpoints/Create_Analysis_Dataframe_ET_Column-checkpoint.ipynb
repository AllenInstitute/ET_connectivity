{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b28d84aa",
   "metadata": {},
   "source": [
    "# Generate ET cell output tables from the proofread table and add putative cell type information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377f8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pcg_skel\n",
    "import tqdm\n",
    "from meshparty import meshwork\n",
    "from caveclient import CAVEclient\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "client = CAVEclient('minnie65_phase3_v1')\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456af022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#now = datetime.datetime.utcnow()\n",
    "now = client.materialize.get_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee32975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "skeldir = 'skeletons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f048067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# Defining the HVA/VISp line:\n",
    "\n",
    "xz0 = [237415, 26308]\n",
    "xz1 = [286783, 8960]\n",
    "\n",
    "x0 = xz0[0]\n",
    "x1 = xz1[0]\n",
    "z0 = xz0[1]\n",
    "z1 = xz1[1]\n",
    "\n",
    "def soma_in_hva(pt):\n",
    "    ptz = pt[2]\n",
    "    ptx = pt[0]\n",
    "    x_thresh = x1 + (ptz-z1) * (x0-x1) / (z0-z1)\n",
    "    return ptx > x_thresh\n",
    "\n",
    "def classify_soma(pt):\n",
    "    if np.any(np.isnan(pt)):\n",
    "        return np.nan\n",
    "        \n",
    "    if soma_in_hva(pt):\n",
    "        return 'hva'\n",
    "    else:\n",
    "        return 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "#before materialization\n",
    "et_df = client.materialize.live_live_query(\n",
    "    \"l5et_column\",\n",
    "    timestamp=\"now\",\n",
    "    joins=[[\"l5et_column\", \"target_id\", \"nucleus_detection_v0\", \"id\"]],\n",
    "    suffixes={'l5et_column': '', 'nucleus_detection_v0': '_ref'},\n",
    "    metadata=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c0b5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#after materialization\n",
    "et_table = 'l5et_column'\n",
    "et_df = client.materialize.query_table(et_table,timestamp = now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d33a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:08, 21.68s/it]"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "# Build the skeletons\n",
    "nrns = {}\n",
    "\n",
    "for _, row in tqdm.tqdm(et_df.iterrows()):\n",
    "\n",
    "    #print(row)\n",
    "    if os.path.exists(f\"{skeldir}/{row['pt_root_id']}.h5\"):\n",
    "        nrns[row[\"pt_root_id\"]] = meshwork.load_meshwork(f\"{skeldir}/{row['pt_root_id']}.h5\")\n",
    "   \n",
    "    else:\n",
    "    \n",
    "        nrns[row[\"pt_root_id\"]] = pcg_skel.coord_space_meshwork(\n",
    "            row[\"pt_root_id\"],\n",
    "            client=client,\n",
    "            root_point=row[\"pt_position\"],\n",
    "            root_point_resolution=[4, 4, 40],\n",
    "            collapse_soma=True,\n",
    "            synapses=\"all\",\n",
    "            synapse_table=client.info.get_datastack_info().get(\"synapse_table\"),\n",
    "            timestamp = now,\n",
    "        )\n",
    "\n",
    "        nrns[row[\"pt_root_id\"]].save_meshwork(f\"{skeldir}/{row['pt_root_id']}.h5\")        \n",
    "        \n",
    "# Get the axons\n",
    "for rid, nrn in nrns.items():\n",
    "    is_axon = meshwork.algorithms.split_axon_by_annotation(\n",
    "        nrn,\n",
    "        'pre_syn',\n",
    "        'post_syn',\n",
    "        return_quality=False\n",
    "    )\n",
    "    nrn.anno.add_annotations('is_axon', is_axon, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326311b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "#Filter for presynaptic outputs on ET cell axons and concatenate into one dataframe:\n",
    "\n",
    "pre_dfs = []\n",
    "for rid in et_df[\"pt_root_id\"]:\n",
    "    df = nrns[rid].anno.pre_syn.filter_query(\n",
    "            nrns[rid].anno.is_axon.mesh_mask\n",
    "    ).df\n",
    "    df.attrs = {}\n",
    "    pre_dfs.append(df)\n",
    "\n",
    "et_pre_df = pd.concat(pre_dfs, ignore_index=True)    \n",
    "\n",
    "et_pre_df['pre_pt_root_id'] = client.chunkedgraph.get_roots(et_pre_df['pre_pt_supervoxel_id'], timestamp=now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Filter for presynaptic outputs on ET cell axons and concatenate into one dataframe, adding synapse distance:\n",
    "\n",
    "pre_dfs = []\n",
    "for rid in et_df[\"pt_root_id\"]:\n",
    "    syn_filt = nrns[rid].anno.pre_syn.filter_query(\n",
    "            nrns[rid].anno.is_axon.mesh_mask\n",
    "    )\n",
    "    df = syn_filt.df\n",
    "    df['dist_to_root'] = nrns[rid].distance_to_root(syn_filt.mesh_index)\n",
    "    df['distance_rank'] = df['dist_to_root'].rank()\n",
    "    df.attrs = {}\n",
    "    pre_dfs.append(df)\n",
    "\n",
    "et_pre_df= pd.concat(pre_dfs, ignore_index=True)\n",
    "et_pre_df['pre_pt_root_id'] = client.chunkedgraph.get_roots(et_pre_df['pre_pt_supervoxel_id'], timestamp=now)\n",
    "et_pre_df['post_pt_root_id'] = client.chunkedgraph.get_roots(et_pre_df['post_pt_supervoxel_id'], timestamp=now).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Add nucleus ID to dataframe\n",
    "\n",
    "et_df_new = et_df.rename(columns={\"pt_root_id\": \"pre_pt_root_id\"})\n",
    "\n",
    "et_pre_df = (\n",
    "    et_pre_df.merge(\n",
    "        et_df_new[[\"pre_pt_root_id\", \"id_ref\"]].rename(\n",
    "            columns={\"id_ref\": \"pre_nucleus_id\"}\n",
    "        ),\n",
    "        on=\"pre_pt_root_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644451f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "\n",
    "preLIST = et_pre_df.pre_pt_root_id.unique()\n",
    "maxLIST = []\n",
    "\n",
    "for pre in preLIST:\n",
    "    res = [pre,max(et_pre_df[(et_pre_df['pre_pt_root_id'] == pre)].distance_rank)]\n",
    "    maxLIST.append(res)\n",
    "  \n",
    "maxLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45230a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# Get single soma root ids and add cell types\n",
    "\n",
    "soma_df = client.materialize.query_table(\n",
    "    \"nucleus_neuron_svm\", filter_equal_dict={\"cell_type\": \"neuron\"}\n",
    ")\n",
    "\n",
    "\n",
    "# Add number of post_synaptic soma on a segment ID\n",
    "soma_df['count_soma'] = soma_df.groupby('pt_root_id').transform('count')['id']\n",
    "num_soma_df = soma_df.drop_duplicates(subset='pt_root_id')[['pt_root_id', 'count_soma']].rename(\n",
    "    columns={\"count_soma\": \"num_soma\"})\n",
    "num_soma_df = num_soma_df.drop_duplicates(subset=\"pt_root_id\", keep='first')\n",
    "\n",
    "\n",
    "def number_of_soma(row):               \n",
    "    if pd.isna(row['num_soma']) == True:\n",
    "          return 0    \n",
    "    else:\n",
    "          return row['num_soma']  \n",
    "num_soma_df['num_soma'] = num_soma_df.apply(number_of_soma, axis=1)\n",
    "\n",
    "\n",
    "# Remove all duplicates\n",
    "soma_df = soma_df.drop_duplicates(subset=\"pt_root_id\", keep='first')\n",
    "\n",
    "# Download all the other tables we want to pull info from\n",
    "NEURD_df = client.materialize.query_table(\"baylor_e_i_model_v1\").drop_duplicates('pt_root_id', keep=False)\n",
    "\n",
    "metamodel_df = client.materialize.query_table(\n",
    "    \"aibs_soma_nuc_metamodel_preds_v117\",\n",
    "    filter_equal_dict={\"classification_system\": \"aibs_neuronal\"},\n",
    ").drop_duplicates('pt_root_id', keep=False)\n",
    "\n",
    "mtypes_model_df = client.materialize.query_table(\n",
    "    \"aibs_soma_nuc_exc_mtype_preds_v117\",\n",
    "    filter_equal_dict={\"classification_system\": \"aibs_coarse_excitatory\"},\n",
    ").drop_duplicates('pt_root_id', keep=False)\n",
    "\n",
    "column_mtypes_df = client.materialize.query_table(\n",
    "    \"allen_column_mtypes_v1\",\n",
    "    filter_equal_dict={\"classification_system\": \"excitatory\"},\n",
    ").drop_duplicates('pt_root_id', keep=False)\n",
    "\n",
    "motif_df = client.materialize.query_table(\"connectivity_groups_v507\").drop_duplicates('pt_root_id', keep=False)\n",
    "\n",
    "\n",
    "# Enrich soma_df with all this info\n",
    "soma_df = (\n",
    "    soma_df.merge(\n",
    "        NEURD_df[[\"pt_root_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"NEURD_class\"}\n",
    "        ),\n",
    "        on=\"pt_root_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        metamodel_df[[\"pt_root_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"metamodel_cell_type\"}\n",
    "        ),\n",
    "        on=\"pt_root_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        mtypes_model_df[[\"pt_root_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"mtypes_model_cell_type\"}\n",
    "        ),\n",
    "        on=\"pt_root_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "       column_mtypes_df[[\"pt_root_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"mtypes_column\"}\n",
    "        ),\n",
    "        on=\"pt_root_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "       motif_df[[\"pt_root_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"motif_group\"}\n",
    "        ),\n",
    "        on=\"pt_root_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Add class labels to soma_df\n",
    "def standard_class_metamodel(row):\n",
    "        \n",
    "    if row['metamodel_cell_type'] == 'MC':\n",
    "          return 'inhibitory'\n",
    " \n",
    "    if row['metamodel_cell_type'] == 'BC':\n",
    "          return 'inhibitory'\n",
    "          \n",
    "    if row['metamodel_cell_type'] == 'NGC':\n",
    "          return 'inhibitory'\n",
    "        \n",
    "    if row['metamodel_cell_type'] == 'BPC':\n",
    "          return 'inhibitory'\n",
    "     \n",
    "    if row['metamodel_cell_type'] == 'none':\n",
    "          return None\n",
    "               \n",
    "    if pd.isna(row['metamodel_cell_type']) == True:\n",
    "          return None\n",
    "        \n",
    "    else:\n",
    "          return 'excitatory' \n",
    "\n",
    "soma_df['metamodel_class'] = soma_df.apply(standard_class_metamodel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ca677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize class labels\n",
    "def standard_class_NEURD(row):\n",
    "        \n",
    "    if pd.isna(row['NEURD_class']) == True:\n",
    "          return None\n",
    "    else:\n",
    "          return row['NEURD_class']  \n",
    "\n",
    "soma_df['NEURD_class'] = soma_df.apply(standard_class_NEURD, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize sub_class labels\n",
    "def standard_subclass_metamodel(row):\n",
    "        \n",
    "    if row['metamodel_cell_type'] == '6P-IT':\n",
    "          return '6P'\n",
    "\n",
    "    if row['metamodel_cell_type'] == '6P-CT':\n",
    "          return '6P'\n",
    "    \n",
    "    if pd.isna(row['metamodel_cell_type']) == True:\n",
    "          return None\n",
    "    else:\n",
    "          return row['metamodel_cell_type']  \n",
    "\n",
    "soma_df['metamodel_cell_type'] = soma_df.apply(standard_subclass_metamodel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize sub_class labels\n",
    "def standard_subclass_mytpes(row):\n",
    "        \n",
    "    if row['mtypes_column'] == 'L3c':\n",
    "          return '23P'\n",
    "    \n",
    "    if row['mtypes_column'] == 'L5ET':\n",
    "          return '5P-ET'\n",
    "\n",
    "    if row['mtypes_column'] == 'L2b':\n",
    "          return '23P'\n",
    "        \n",
    "    if row['mtypes_column'] == 'L6a':\n",
    "          return '6P'\n",
    "  \n",
    "    if row['mtypes_column'] == 'L4c':\n",
    "          return '4P'\n",
    "        \n",
    "    if row['mtypes_column'] == 'L6c':\n",
    "          return '6P'\n",
    "        \n",
    "    if row['mtypes_column'] == 'L6CT':\n",
    "          return '6P'\n",
    "        \n",
    "    if row['mtypes_column'] == 'L6b':\n",
    "          return '6P'\n",
    "        \n",
    "    if row['mtypes_column'] == 'L4a':\n",
    "          return '4P'\n",
    "        \n",
    "    if row['mtypes_column'] == 'L2a':\n",
    "          return '23P'\n",
    "        \n",
    "    if row['mtypes_column'] == 'L3b':\n",
    "          return '23P'\n",
    "        \n",
    "    if row['mtypes_column'] == 'L3a':\n",
    "          return '23P'\n",
    "\n",
    "    if row['mtypes_column'] == 'L5b':\n",
    "          return '5P-IT'\n",
    "\n",
    "    if row['mtypes_column'] == 'L4b':\n",
    "          return '4P'\n",
    "\n",
    "    if row['mtypes_column'] == 'L5a':\n",
    "          return '5P-IT'\n",
    "\n",
    "    if row['mtypes_column'] == 'L5NP':\n",
    "          return '5P-NP'\n",
    "\n",
    "    if row['mtypes_column'] == 'L6wm':\n",
    "          return '6P'\n",
    "\n",
    "    if pd.isna(row['mtypes_column']) == True:\n",
    "          return None\n",
    "    else:\n",
    "          return row['mtypes_column']  \n",
    "\n",
    "soma_df['mtypes_column'] = soma_df.apply(standard_subclass_mytpes, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize sub_class labels\n",
    "def standard_subclass_mytpes_model(row):\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L3c':\n",
    "          return '23P'\n",
    "    \n",
    "    if row['mtypes_model_cell_type'] == 'L5ET':\n",
    "          return '5P-ET'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L2b':\n",
    "          return '23P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L6a':\n",
    "          return '6P'\n",
    "  \n",
    "    if row['mtypes_model_cell_type'] == 'L4c':\n",
    "          return '4P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L6c':\n",
    "          return '6P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L6CT':\n",
    "          return '6P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L6b':\n",
    "          return '6P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L4a':\n",
    "          return '4P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L2a':\n",
    "          return '23P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L3b':\n",
    "          return '23P'\n",
    "        \n",
    "    if row['mtypes_model_cell_type'] == 'L3a':\n",
    "          return '23P'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L5b':\n",
    "          return '5P-IT'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L4b':\n",
    "          return '4P'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L5a':\n",
    "          return '5P-IT'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L5NP':\n",
    "          return '5P-NP'\n",
    "\n",
    "    if row['mtypes_model_cell_type'] == 'L6wm':\n",
    "          return '6P'\n",
    "\n",
    "    if pd.isna(row['mtypes_model_cell_type']) == True:\n",
    "          return None\n",
    "    else:\n",
    "          return row['mtypes_model_cell_type']  \n",
    "\n",
    "soma_df['mtypes_model_cell_type'] = soma_df.apply(standard_subclass_mytpes_model, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ba61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Merge all this info from cell types into the synapse dataframe, as well as add area locations.\n",
    "\n",
    "#merge presynaptic nucleous ID\n",
    "synapse_table = et_pre_df.merge(\n",
    "    soma_df[\n",
    "        [\"id\", \"pt_root_id\", \"pt_position\",  \"NEURD_class\", \"metamodel_class\", \"metamodel_cell_type\",\"mtypes_model_cell_type\",\"mtypes_column\",\"motif_group\"]\n",
    "    ].rename(columns={\"pt_position\": \"post_soma_pt\"}).rename(columns={\"id\": \"post_nucleus_id\"}),\n",
    "    left_on=\"post_pt_root_id\",\n",
    "    right_on=\"pt_root_id\",\n",
    "    how=\"left\",\n",
    ").drop(columns=\"pt_root_id\")\n",
    "\n",
    "synapse_table[\"post_soma_area\"] = synapse_table['post_soma_pt'].apply(classify_soma)\n",
    "\n",
    "synapse_table = synapse_table.merge(\n",
    "    et_df[['pt_root_id', 'pt_position']].rename(columns={'pt_position': 'pre_soma_pt'}),\n",
    "    left_on='pre_pt_root_id',\n",
    "    right_on='pt_root_id',\n",
    "    how='left',\n",
    ").drop(columns='pt_root_id')\n",
    "\n",
    "synapse_table[\"pre_soma_area\"] = synapse_table['pre_soma_pt'].apply(classify_soma)\n",
    "\n",
    "synapse_table = synapse_table.rename(columns={\"cell_type_pred\": \"aibs_auto_subclass\"})\n",
    "\n",
    "\n",
    "# addition by Nuno\n",
    "# load manual label\n",
    "\n",
    "manual_multi_df = client.materialize.live_live_query(\n",
    "    'pt_synapse_targets',\n",
    "    timestamp=\"now\",\n",
    "    metadata=False,\n",
    ")\n",
    "#manual_multi_df = client.materialize.query_table(\"pt_synapse_targets\")\n",
    "manual_multi_df = manual_multi_df.rename(columns={\"target_id\": \"synapse_id\"})\n",
    "#manual_multi_df = client.materialize.query_table(\"pt_synapse_targets\").drop_duplicates('post_pt_root_id', keep=False)\n",
    "#manual_multi_df['post_pt_root_id'] = manual_multi_df.post_pt_root_id.astype('UInt64')\n",
    "\n",
    "\n",
    "#manual_multi_df = pd.read_feather('manual_pt.feather')\n",
    "\n",
    "synapse_table = synapse_table.rename(columns={\"id\": \"synapse_id\"})\n",
    "\n",
    "\n",
    "#merge manual labels\n",
    "\n",
    "synapse_table = (\n",
    "    synapse_table.merge(\n",
    "        manual_multi_df[[\"synapse_id\", \"classification_system\"]].rename(\n",
    "            columns={\"classification_system\": \"manual_class\"}\n",
    "        ),\n",
    "        on='synapse_id',\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        manual_multi_df[[\"synapse_id\", \"cell_type\"]].rename(\n",
    "            columns={\"cell_type\": \"manual_subclass\"}\n",
    "        ),\n",
    "        on='synapse_id',\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        num_soma_df[[\"pt_root_id\", \"num_soma\"]],\n",
    "        left_on='post_pt_root_id',\n",
    "        right_on='pt_root_id',\n",
    "        how=\"left\",\n",
    "    ).drop(columns='pt_root_id')\n",
    ")\n",
    "\n",
    "\n",
    "def number_of_soma(row):               \n",
    "    if pd.isna(row['num_soma']) == True:\n",
    "          return 0    \n",
    "    else:\n",
    "          return row['num_soma']  \n",
    "synapse_table['num_soma'] = synapse_table.apply(number_of_soma, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db034c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize class labels from manual\n",
    "def standard_class_man(row):\n",
    "        \n",
    "    if row['manual_class'] == 'none':\n",
    "          return None        \n",
    "\n",
    "    if pd.isna(row['manual_class']) == True:\n",
    "          return None\n",
    "         \n",
    "    else:\n",
    "          return row['manual_class']  \n",
    "\n",
    "synapse_table['manual_class'] = synapse_table.apply(standard_class_man, axis=1)\n",
    "\n",
    "synapse_table = synapse_table[(synapse_table['manual_class'] != 'error')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#standardize sub_class labels\n",
    "def standard_subclass_man(row):\n",
    "        \n",
    "    if row['manual_subclass'] == 'multisoma':\n",
    "          return None\n",
    "\n",
    "    if row['manual_subclass'] == 'DTC':\n",
    "          return 'MC'               \n",
    "               \n",
    "    if row['manual_subclass'] == 'none':\n",
    "          return None\n",
    "        \n",
    "    if row['manual_subclass'] == '5P-PT':\n",
    "          return '5P-ET'\n",
    "\n",
    "    if row['manual_subclass'] == 'unclear':\n",
    "          return None\n",
    "                 \n",
    "    if pd.isna(row['manual_subclass']) == True:\n",
    "          return None\n",
    "    else:\n",
    "          return row['manual_subclass']  \n",
    "\n",
    "synapse_table['manual_subclass'] = synapse_table.apply(standard_subclass_man, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# create new column indicating which neurons are in \n",
    "# Group 1 (non-ET prefereing interneurons) and Group 2 (ET-prefering Interneurons)\n",
    "\n",
    "#create new column 'inhibitory groups'\n",
    "def create_inhibitory_groups(row):\n",
    "\n",
    "    Group2 = [269633, 305251,269414,267006,305232,303195,271673,269585,292721,\n",
    "          304990,305233,269485,269334,305046,303172, 267293,302962]\n",
    "    \n",
    "    if pd.isna(row['motif_group']) == True:\n",
    "          return 0\n",
    "    else:\n",
    "    \n",
    "        if row['post_nucleus_id'] in  Group2:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "synapse_table['inhibitory_groups'] = synapse_table.apply(create_inhibitory_groups, axis=1)\n",
    "\n",
    "\n",
    "synapse_table.inhibitory_groups.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb326ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#QC - CHECK IF THERE ARE DFERRENT MANUAL CLASS LABELS ASIGNED TO THE SAME NEURON \n",
    "\n",
    "for ii in synapse_table.post_pt_root_id.unique():\n",
    "\n",
    "    if len(synapse_table[(synapse_table['post_pt_root_id'] == ii) &\n",
    "                    pd.notna(synapse_table['manual_class'])].manual_class.unique()) > 1:\n",
    "    #if len(synapse_table[(synapse_table['post_pt_root_id'] == ii) & (synapse_table['num_soma'] < 2) &\n",
    "    #                pd.notna(synapse_table['manual_class'])].manual_class.unique()) > 1:\n",
    "        print(ii)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c78d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#QC - CHECK IF THERE ARE DFERRENT MANUAL SUBCLASS LABELS ASIGNED TO THE SAME NEURON \n",
    "\n",
    "for ii in synapse_table.post_pt_root_id.unique():\n",
    "\n",
    "    if len(synapse_table[(synapse_table['post_pt_root_id'] == ii) & (synapse_table['num_soma'] < 2) \n",
    "                         & pd.notna(synapse_table['manual_subclass'])].manual_subclass.unique()) > 1:\n",
    "        print(ii)\n",
    "        \n",
    "    if len(synapse_table[(synapse_table['post_pt_root_id'] == ii) & (synapse_table['num_soma'] < 2) \n",
    "                         & pd.notna(synapse_table['manual_subclass'])].manual_subclass.unique()) > 1:\n",
    "\n",
    "        print(ii) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#TRANSFER MANUAL SUBCLASS LABELS ACROSS SYNAPSES OF THE SAME NEURON\n",
    "\n",
    "#Create df with subclass labels and only one post_pt_root_id for IDs that are single somas or orphans\n",
    "manual_subclass_labels = synapse_table[(synapse_table['num_soma'] <= 1) &\n",
    "                                      pd.notna(synapse_table['manual_subclass'])].drop_duplicates(subset='post_pt_root_id')\n",
    "\n",
    "manual_subclass_labels = manual_subclass_labels[['post_pt_root_id', 'manual_subclass']] \n",
    "\n",
    "#Transfer the subclass labels using the merge function \n",
    "#(In an earlier version I created a new table after this point \"#synapse_table_transfer\")\n",
    "\n",
    "synapse_table = synapse_table.merge(manual_subclass_labels, left_on='post_pt_root_id',\n",
    "                                                      right_on='post_pt_root_id', how='left')\n",
    "\n",
    "#Transfer the subclass labels on multisoma\n",
    "def subclass_transfer(row):\n",
    "   \n",
    "    if pd.isna(row['manual_subclass_y']) == True:\n",
    "          return row['manual_subclass_x']\n",
    "   \n",
    "    else:\n",
    "          return row['manual_subclass_y']  \n",
    "\n",
    "synapse_table['manual_subclass_y'] = synapse_table.apply(subclass_transfer, axis=1)\n",
    "\n",
    "#Rename columns\n",
    "synapse_table = synapse_table.rename(columns={\"manual_subclass_x\": \"manual_subclass_original\",\n",
    "                                                                \"manual_subclass_y\": \"manual_subclass\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af763f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#TRANSFER MANUAL CLASS LABELS ACROSS SYNAPSES OF THE SAME NEURON\n",
    "\n",
    "#Create df with subclass labels and only one post_pt_root_id for IDs that are single somas or orphans\n",
    "manual_class_labels = synapse_table[(synapse_table['num_soma'] <= 1) &\n",
    "                                      pd.notna(synapse_table['manual_class'])].drop_duplicates(subset='post_pt_root_id')\n",
    "\n",
    "manual_class_labels = manual_class_labels[['post_pt_root_id', 'manual_class']] \n",
    "\n",
    "#Transfer the subclass labels using the merge function\n",
    "synapse_table = synapse_table.merge(manual_class_labels, left_on='post_pt_root_id',\n",
    "                                                      right_on='post_pt_root_id', how='left')\n",
    "\n",
    "#Transfer multisoma labels\n",
    "def class_transfer(row):\n",
    "   \n",
    "    if pd.isna(row['manual_class_y']) == True:\n",
    "          return row['manual_class_x']\n",
    "   \n",
    "    else:\n",
    "          return row['manual_class_y']  \n",
    "\n",
    "synapse_table['manual_class_y'] = synapse_table.apply(class_transfer, axis=1)\n",
    "\n",
    "#Rename columns\n",
    "synapse_table = synapse_table.rename(columns={\"manual_class_x\": \"manual_class_original\",\n",
    "                                              \"manual_class_y\": \"manual_class\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2aba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#QC - CHECK IF THE MANUAL CLASS AND SUBCLASS ARE CONSISTENT\n",
    "\n",
    "#create new column where class is calculated from subclass\n",
    "def create_class_from_subclass(row):\n",
    "    if row['manual_subclass'] == '5P-NP':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '5P-ET':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '5P-IT':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '4P':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '6P':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == '23P':\n",
    "          return 'excitatory'\n",
    "    if row['manual_subclass'] == 'BC':\n",
    "          return 'inhibitory'\n",
    "    if row['manual_subclass'] == 'MC':\n",
    "          return 'inhibitory'\n",
    "    if row['manual_subclass'] == 'BPC':\n",
    "          return 'inhibitory'\n",
    "    else:\n",
    "          return row['manual_subclass']\n",
    "\n",
    "synapse_table['class_from_subclass'] = synapse_table.apply(create_class_from_subclass, axis=1)\n",
    "\n",
    "\n",
    "def check_class_from_subclass(row):\n",
    "   \n",
    "    if row['manual_class'] == row['class_from_subclass']:\n",
    "          return 'OK'\n",
    "   \n",
    "    else:\n",
    "          return row['manual_subclass']  \n",
    "\n",
    "synapse_table['check_class_from_subclass'] = synapse_table.apply(check_class_from_subclass, axis=1)\n",
    "\n",
    "synapse_table.check_class_from_subclass.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b41252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#QC - CHECK DISAGREEMENT BETWEEN NEURD and metamodel LABELS\n",
    "\n",
    "manual_check1 = synapse_table[(synapse_table['NEURD_class'] == 'excitatory') \n",
    "              & (synapse_table['metamodel_class'] == 'inhibitory') & pd.isna(synapse_table['manual_class'])].drop_duplicates(subset='post_pt_root_id')#.post_pt_root_id.unique()\n",
    "\n",
    "print('number of unchecked disagreements where NEURD is \"E\" and metamodel is \"I\": ', len(manual_check1))\n",
    "\n",
    "\n",
    "manual_check2 = synapse_table[(synapse_table['NEURD_class'] == 'inhibitory') \n",
    "              & (synapse_table['metamodel_class'] == 'excitatory') & pd.isna(synapse_table['manual_class'])].drop_duplicates(subset='post_pt_root_id')#.post_pt_root_id.unique()\n",
    "\n",
    "print('number of unchecked disagreements where NEURD is \"I\" and metamodel is \"E\": ', len(manual_check2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#QC - CHECK FOR LABELS WITH NO ENTRIES\n",
    "\n",
    "manual_check = synapse_table[pd.isna(synapse_table['NEURD_class']) \n",
    "              & pd.isna(synapse_table['metamodel_cell_type']) & pd.isna(synapse_table['manual_class'])].drop_duplicates(subset='post_pt_root_id')#.post_pt_root_id.unique()\n",
    "\n",
    "manual_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfecb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#INTEGRATE CLASS LABELS BETWEEN MANUAL AND AUTOMATED LABELS\n",
    "\n",
    "#generate new consensus column\n",
    "synapse_table['consensus_class'] = synapse_table['manual_class']\n",
    "\n",
    "#When there isn't manual label add aibs_v2 label\n",
    "\n",
    "def integrate_class(row):\n",
    "    if row['consensus_class'] == None:\n",
    "          return row['metamodel_class']\n",
    "    \n",
    "    else:\n",
    "          return row['consensus_class']  \n",
    "\n",
    "synapse_table['consensus_class'] = synapse_table.apply(integrate_class, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#INTEGRATE SUBCLASS LABELS BETWEEN MANUAL AND AUTOMATED LABELS\n",
    "\n",
    "#generate new consensus column\n",
    "synapse_table['consensus_subclass'] = synapse_table['manual_subclass']\n",
    "\n",
    "#When there isn't manual label add aibs_v2 label\n",
    "\n",
    "def integrate_subclass(row):\n",
    "    if row['consensus_subclass'] == None:\n",
    "          return row['metamodel_cell_type']\n",
    "    if row['consensus_subclass'] == 'inhibitory':\n",
    "          return None      \n",
    "    \n",
    "    else:\n",
    "          return row['consensus_subclass']  \n",
    "\n",
    "synapse_table['consensus_subclass'] = synapse_table.apply(integrate_subclass, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b47e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#QC - CHECK IF THE INTEGRATED CLASS AND SUBCLASS ARE CONSISTENT\n",
    "\n",
    "#remove previous columns\n",
    "synapse_table = synapse_table.drop(['class_from_subclass', 'check_class_from_subclass'], axis=1)\n",
    "#synapse_table = synapse_table.drop(['class_from_subclass'], axis=1)\n",
    "\n",
    "\n",
    "#create new column where class is calculated from subclass\n",
    "def create_class_from_subclass(row):\n",
    "    if row['consensus_subclass'] == '5P-NP':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '5P-ET':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '5P-IT':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '4P':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '6P':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '6P-IT':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '6P-CT':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == '23P':\n",
    "          return 'excitatory'\n",
    "    if row['consensus_subclass'] == 'BC':\n",
    "          return 'inhibitory'\n",
    "    if row['consensus_subclass'] == 'MC':\n",
    "          return 'inhibitory'\n",
    "    if row['consensus_subclass'] == 'NGC':\n",
    "          return 'inhibitory'\n",
    "    if row['consensus_subclass'] == 'BPC':\n",
    "          return 'inhibitory'\n",
    "    if row['consensus_subclass'] == 'inhibitory':\n",
    "          return 'unknown'        \n",
    "        \n",
    "    else:\n",
    "          return row['consensus_subclass']\n",
    "\n",
    "synapse_table['class_from_subclass'] = synapse_table.apply(create_class_from_subclass, axis=1)\n",
    "\n",
    "\n",
    "def check_class_from_subclass(row):\n",
    "   \n",
    "    if row['consensus_class'] == row['class_from_subclass']:\n",
    "          return 'OK'\n",
    "   \n",
    "    else:\n",
    "          return row['consensus_subclass']  \n",
    "\n",
    "synapse_table['check_class_from_subclass'] = synapse_table.apply(check_class_from_subclass, axis=1)\n",
    "\n",
    "synapse_table.check_class_from_subclass.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ce8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_table[synapse_table['check_class_from_subclass'] == '6P-IT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92744582",
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_table.manual_subclass_original.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cfd781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NEUROGLANCER LINK\n",
    "\n",
    "\n",
    "manual_check = synapse_table[(synapse_table['synapse_id']== 177039637)].drop_duplicates(subset='post_pt_root_id')\n",
    "#manual_check = synapse_table[(synapse_table['manual_eiaibs_subclass']== '5P-PT') & (synapse_table['pre_pt_root_id']==864691135293076662)].drop_duplicates(subset='post_pt_root_id')\n",
    "#manual_check = manual_check.drop_duplicates(subset='post_pt_root_id')\n",
    "\n",
    "\n",
    "from nglui import statebuilder\n",
    "\n",
    "img, seg = statebuilder.from_client(client)\n",
    "\n",
    "pt_map = statebuilder.PointMapper('post_pt_position', linked_segmentation_column='post_pt_root_id')\n",
    "anno = statebuilder.AnnotationLayerConfig('post_pt_position', mapping_rules=pt_map, linked_segmentation_layer=seg.name,\n",
    "                                          tags=['single_spine','dendrite', 'error', 'has_soma'])\n",
    "sb = statebuilder.StateBuilder([img, seg, anno], client=client)\n",
    "\n",
    "#here is where you add the dataframe\n",
    "sb.render_state(manual_check[['post_pt_root_id','post_pt_position']], return_as='html')\n",
    "\n",
    "#[id, x,y,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a43312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#SAVE AND READ\n",
    "\n",
    "#remove columns before saving\n",
    "#synapse_table = synapse_table.drop(['class_from_subclass', 'check_class_from_subclass'], axis=1)\n",
    "\n",
    "\n",
    "#save et_pre_ct_df\n",
    "synapse_table = synapse_table[synapse_table['distance_rank'] < 101]\n",
    "synapse_table.reset_index(drop=True).to_feather(\"ET_Column_synapse_table.feather\")\n",
    "\n",
    "#READ\n",
    "#et_pre_ct_df = pd.read_feather('ET_Column_syn_df_NC.feather')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857e9b9",
   "metadata": {},
   "source": [
    "# EXTRAS TO BE DELETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "\n",
    "#ANALYSIS - FIGURE 2.g\n",
    "#percentage of Inhibitory group 2 targets\n",
    "\n",
    "\n",
    "#number of synapses with Inhibitory group 1 targets\n",
    "group1 = len(synapse_table[(synapse_table['inhibitory_groups'] ==  1)])\n",
    "\n",
    "#number of synapses with Inhibitory group 2 targets\n",
    "group2 = len(synapse_table[(synapse_table['inhibitory_groups'] ==  2)])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('_mpl-gallery')\n",
    "\n",
    "# make data:\n",
    "np.random.seed(3)\n",
    "x = ['Group 1', 'Group 2']\n",
    "y = [group1, group2]\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(x, y, width=1, edgecolor=\"white\", linewidth=0.5)\n",
    "\n",
    "#ax.set(xlim=(0, 8), xticks=np.arange(1, 8),\n",
    "#       ylim=(0, 8), yticks=np.arange(1, 8))\n",
    "\n",
    "fig.savefig('Column_inhibitory_groups_input.eps', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fbfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "\n",
    "#ANALYSIS - FIGURE 2.f\n",
    "#percentage of Inhibitory group 2 targets\n",
    "#after materialization\n",
    "\n",
    "\n",
    "column_table = 'allen_column_mtypes_v1'\n",
    "column_table_df = client.materialize.query_table(column_table,timestamp = now)\n",
    "\n",
    "\n",
    "all_ids = column_table_df.id_ref.values\n",
    "\n",
    "\n",
    "column_table_I_df = column_table_df[(column_table_df['classification_system'] ==  'inhibitory')]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# crop dataframe to incliude ony synapses with column neurons\n",
    "\n",
    "def create_column_neurons(row):\n",
    "\n",
    "#    GroupET = column_table_df[column_table_df['cell_type'] == 'L5ET'].target_id.values\n",
    "#    \n",
    "#    Group2 = [269633, 305251,269414,267006,305232,303195,271673,269585,292721,\n",
    "#          304990,305233,269485,269334,305046,303172, 267293,302962]\n",
    "    \n",
    "    if row['post_nucleus_id'] in GroupET:\n",
    "    \n",
    "        if row['pre_nucleus_id'] in  Group2:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "column_table_I_pre_df['inhibitory_groups'] = column_table_I_pre_df.apply(create_inhibitory_groups, axis=1)\n",
    "\n",
    "\n",
    "column_table_I_pre_df.inhibitory_groups.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17858a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_I_df = column_table_df[(column_table_df['classification_system'] ==  'inhibitory')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_df.classification_system.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817de5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_I_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# Build the skeletons\n",
    "nrns = {}\n",
    "\n",
    "for _, row in tqdm.tqdm(column_table_I_df.iterrows()):\n",
    "\n",
    "    #print(row)\n",
    "    if os.path.exists(f\"{skeldir}/{row['pt_root_id']}.h5\"):\n",
    "        nrns[row[\"pt_root_id\"]] = meshwork.load_meshwork(f\"{skeldir}/{row['pt_root_id']}.h5\")\n",
    "   \n",
    "    else:\n",
    "    \n",
    "        nrns[row[\"pt_root_id\"]] = pcg_skel.coord_space_meshwork(\n",
    "            row[\"pt_root_id\"],\n",
    "            client=client,\n",
    "            root_point=row[\"pt_position\"],\n",
    "            root_point_resolution=[4, 4, 40],\n",
    "            collapse_soma=True,\n",
    "            synapses=\"all\",\n",
    "            synapse_table=client.info.get_datastack_info().get(\"synapse_table\"),\n",
    "            timestamp = now,\n",
    "        )\n",
    "\n",
    "        nrns[row[\"pt_root_id\"]].save_meshwork(f\"{skeldir}/{row['pt_root_id']}.h5\")        \n",
    "        \n",
    "# Get the axons\n",
    "for rid, nrn in nrns.items():\n",
    "    is_axon = meshwork.algorithms.split_axon_by_annotation(\n",
    "        nrn,\n",
    "        'pre_syn',\n",
    "        'post_syn',\n",
    "        return_quality=False\n",
    "    )\n",
    "    nrn.anno.add_annotations('is_axon', is_axon, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0facdba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "#Filter for presynaptic outputs on ET cell axons and concatenate into one dataframe:\n",
    "\n",
    "pre_dfs = []\n",
    "for rid in column_table_I_df[\"pt_root_id\"]:\n",
    "    df = nrns[rid].anno.pre_syn.filter_query(\n",
    "            nrns[rid].anno.is_axon.mesh_mask\n",
    "    ).df\n",
    "    df.attrs = {}\n",
    "    pre_dfs.append(df)\n",
    "\n",
    "column_table_I_pre_df = pd.concat(pre_dfs, ignore_index=True)    \n",
    "\n",
    "column_table_I_pre_df['pre_pt_root_id'] = client.chunkedgraph.get_roots(column_table_I_pre_df['pre_pt_supervoxel_id'], timestamp=now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8028fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge postynaptic nucleous ID\n",
    "column_table_I_pre_df = column_table_I_pre_df.merge(\n",
    "    soma_df[\n",
    "        [\"id\", \"pt_root_id\", \"pt_position\"]\n",
    "    ].rename(columns={\"pt_position\": \"post_soma_pt\"}).rename(columns={\"id\": \"post_nucleus_id\"}),\n",
    "    left_on=\"post_pt_root_id\",\n",
    "    right_on=\"pt_root_id\",\n",
    "    how=\"left\",\n",
    ").drop(columns=\"pt_root_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09456948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Consider only synapses with column neurons\n",
    "\n",
    "def target_column_neurons(row):\n",
    "    \n",
    "    if row['post_nucleus_id'] in all_ids:\n",
    "    \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "column_table_I_pre_df['column_neuron'] = column_table_I_pre_df.apply(target_column_neurons, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d341a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_I_pre_df = column_table_I_pre_df[(column_table_I_pre_df['classification_system'] ==  'inhibitory')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_I_pre_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "#Consider only synapses with column neurons\n",
    "\n",
    "def target_column_neurons(row):\n",
    "\n",
    "#    GroupET = column_table_df[column_table_df['cell_type'] == 'L5ET'].target_id.values\n",
    "#    \n",
    "#    Group2 = [269633, 305251,269414,267006,305232,303195,271673,269585,292721,\n",
    "          304990,305233,269485,269334,305046,303172, 267293,302962]\n",
    "    \n",
    "    if row['post_nucleus_id'] in all_ids:\n",
    "    \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "column_table_I_pre_df['column_neuron'] = column_table_I_pre_df.apply(target_column_neurons, axis=1)\n",
    "\n",
    "\n",
    "column_table_I_pre_df.inhibitory_groups.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac14a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_I_pre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3764880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1875e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_I_pre_df = column_table_I_pre_df.merge(\n",
    "    soma_df[\n",
    "        [\"id\",\"pt_root_id\"]\n",
    "    ].rename(columns={\"id\": \"pre_nucleus_id\"}),\n",
    "    left_on=\"pre_pt_root_id\",\n",
    "    right_on=\"pt_root_id\",\n",
    "    how=\"left\",\n",
    ").drop(columns=\"pt_root_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_I_pre_df.cell_type_pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff3c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# create new column indicating which neurons are in \n",
    "# Group 1 (non-ET prefereing interneurons) and Group 2 (ET-prefering Interneurons)\n",
    "\n",
    "#create new column 'inhibitory groups'\n",
    "def create_inhibitory_groups(row):\n",
    "\n",
    "    GroupET = column_table_df[column_table_df['cell_type'] == 'L5ET'].target_id.values\n",
    "    \n",
    "    Group2 = [269633, 305251,269414,267006,305232,303195,271673,269585,292721,\n",
    "          304990,305233,269485,269334,305046,303172, 267293,302962]\n",
    "    \n",
    "    if row['post_nucleus_id'] in GroupET:\n",
    "    \n",
    "        if row['pre_nucleus_id'] in  Group2:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "column_table_I_pre_df['inhibitory_groups'] = column_table_I_pre_df.apply(create_inhibitory_groups, axis=1)\n",
    "\n",
    "\n",
    "column_table_I_pre_df.inhibitory_groups.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b477d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "\n",
    "#ANALYSIS - FIGURE 2.g\n",
    "#percentage of Inhibitory group 2 targets\n",
    "\n",
    "\n",
    "#number of synapses with Inhibitory group 1 targets\n",
    "group1 = len(synapse_table[(synapse_table['inhibitory_groups'] ==  1)])\n",
    "\n",
    "#number of synapses with Inhibitory group 2 targets\n",
    "group2 = len(synapse_table[(synapse_table['inhibitory_groups'] ==  2)])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('_mpl-gallery')\n",
    "\n",
    "# make data:\n",
    "np.random.seed(3)\n",
    "x = ['Group 1', 'Group 2']\n",
    "y = [group1, group2]\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(x, y, width=1, edgecolor=\"white\", linewidth=0.5)\n",
    "\n",
    "#ax.set(xlim=(0, 8), xticks=np.arange(1, 8),\n",
    "#       ylim=(0, 8), yticks=np.arange(1, 8))\n",
    "\n",
    "fig.savefig('Column_inhibitory_groups_input.eps', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2dc55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_df[column_table_df['cell_type'] == 'L5ET'].target_id.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586baa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_df.cell_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c64a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_I_pre_df = column_table_I_pre_df.drop(columns=\"inhibitory_groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_table_I_pre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9567d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_table[(synapse_table['inhibitory_groups'] ==  1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(synapse_table[(synapse_table['inhibitory_groups'] ==  2)].post_nucleus_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70dc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "#ANALYSIS GENERAL\n",
    "##ANALYSIS - FIGURE 4.a\n",
    "#MAKE STATS DATAFRAME - All synapses and connections\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "percentage = []\n",
    "values = []\n",
    "\n",
    "#IDs of presynaptic PT neurons\n",
    "pre_soma_IDs = All_neurons\n",
    "\n",
    "\n",
    "for ii,pre_soma_ID in enumerate(pre_soma_IDs):        \n",
    "        \n",
    "   \n",
    "    stat_values={\n",
    "\n",
    "                    'ID': pre_soma_ID, \n",
    "                      #SYNAPSES\n",
    "                    \n",
    "                    'all_syn_total': len(synapse_table[ (synapse_table['pre_pt_root_id'] == pre_soma_ID)]),\n",
    "                    'all_e_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_class'] == 'excitatory')]),\n",
    "                    'all_i_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_class'] == 'inhibitory')]),\n",
    "        \n",
    "                    'all_Undetermined_class_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     ((synapse_table['manual_eiaibs_class'] == 'Unsure') |\n",
    "                                      pd.isnull(synapse_table['manual_eiaibs_class']))]),\n",
    "                    \n",
    "        \n",
    "                    'all_23P_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '23P')]),\n",
    "        \n",
    "                    'all_4P_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '4P')]),\n",
    "                    'all_5P-PT_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '5P-PT')]),\n",
    "                    'all_5P-NP_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '5P-NP')]), \n",
    "                    'all_5P-IT_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '5P-IT')]), \n",
    "                \n",
    "                    'all_6P_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '6P')]),\n",
    "        \n",
    "                    'all_BC_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == 'BC')]),\n",
    "        \n",
    "                    'all_MC_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == 'MC')]),\n",
    "        \n",
    "                    'all_BPC_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == 'BPC')]),\n",
    "        \n",
    "                    'all_NGC_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == 'NGC')]),\n",
    "        \n",
    "                    'all_Undetermined_subclass_syn#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     ((synapse_table['manual_eiaibs_subclass'] == 'Unsure') |\n",
    "                                      pd.isnull(synapse_table['manual_eiaibs_subclass']))]),\n",
    "                    \n",
    "        \n",
    "        #CONNECTIONS\n",
    "                    'all_con_total': len(synapse_table[ (synapse_table['pre_pt_root_id'] == pre_soma_ID)]\n",
    "                                         ['post_pt_root_id'].unique()),\n",
    "                    \n",
    "                    'all_e_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_class'] == 'excitatory')]\n",
    "                                      ['post_pt_root_id'].unique()),\n",
    "                    \n",
    "                    'all_i_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_class'] == 'inhibitory')]\n",
    "                                      ['post_pt_root_id'].unique()),\n",
    "        \n",
    "                    'all_Undetermined_class_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     ((synapse_table['manual_eiaibs_class'] == 'Unsure') |\n",
    "                                      pd.isnull(synapse_table['manual_eiaibs_class']))]['post_pt_root_id'].unique()),                      \n",
    "        \n",
    "                    'all_23P_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '23P')]['post_pt_root_id'].unique()),\n",
    "        \n",
    "                    'all_4P_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '4P')]['post_pt_root_id'].unique()),\n",
    "                    \n",
    "                    'all_5P-PT_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '5P-PT')]['post_pt_root_id'].unique()),\n",
    "                    \n",
    "                    'all_5P-NP_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '5P-NP')]['post_pt_root_id'].unique()), \n",
    " \n",
    "                    'all_5P-IT_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '5P-IT')]['post_pt_root_id'].unique()),\n",
    "                    \n",
    "                    'all_6P_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == '6P')]['post_pt_root_id'].unique()),\n",
    "                                    \n",
    "                    'all_BC_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == 'BC')]['post_pt_root_id'].unique()),\n",
    "                     \n",
    "                    'all_MC_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == 'MC')]['post_pt_root_id'].unique()),\n",
    "       \n",
    "                    'all_BPC_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == 'BPC')]['post_pt_root_id'].unique()),\n",
    "                    \n",
    "                    'all_NGC_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     (synapse_table['manual_eiaibs_subclass'] == 'NGC')]['post_pt_root_id'].unique()),\n",
    "        \n",
    "                    'all_Undetermined_subclass_con#': len(synapse_table[(synapse_table['pre_pt_root_id'] == pre_soma_ID) &\n",
    "                                     ((synapse_table['manual_eiaibs_subclass'] == 'Unsure') |\n",
    "                                      pd.isnull(synapse_table['manual_eiaibs_subclass']))]['post_pt_root_id'].unique()),\n",
    "                        \n",
    "        \n",
    "    }\n",
    "    values.append(stat_values)\n",
    "    \n",
    "    \n",
    "    stat_percentage={\n",
    "\n",
    "                    'ID': pre_soma_ID, \n",
    "                      \n",
    "                    'i_syn': stat_values['all_i_syn#'] / stat_values['all_syn_total'],\n",
    "                    'e_syn': stat_values['all_e_syn#'] / stat_values['all_syn_total'],\n",
    "                    'Undetermined_class_syn': stat_values['all_Undetermined_class_syn#'] / stat_values['all_syn_total'],\n",
    "        \n",
    "                    '23P_syn': stat_values['all_23P_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    '4P_syn': stat_values['all_4P_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    '5P-PT_syn': stat_values['all_5P-PT_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    '5P-IT_syn': stat_values['all_5P-IT_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    '5P-NP_syn': stat_values['all_5P-NP_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    '6P_syn': stat_values['all_6P_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    'BC_syn': stat_values['all_BC_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    'MC_syn': stat_values['all_MC_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    'BPC_syn': stat_values['all_BPC_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    'NGC_syn': stat_values['all_NGC_syn#'] / (stat_values['all_syn_total'] - stat_values['all_Undetermined_subclass_syn#']),\n",
    "                    'Undetermined_subclass_syn': stat_values['all_Undetermined_subclass_syn#'] / stat_values['all_syn_total'],\n",
    "        \n",
    "        \n",
    "                    'i_con': stat_values['all_i_con#'] / stat_values['all_con_total'],\n",
    "                    'e_con': stat_values['all_e_con#'] / stat_values['all_con_total'],\n",
    "                    'Undetermined_class_con': stat_values['all_Undetermined_class_con#'] / stat_values['all_con_total'],\n",
    "                   \n",
    "        \n",
    "                    '23P_con': stat_values['all_23P_con#'] / stat_values['all_con_total'],\n",
    "                    '4P_con': stat_values['all_4P_con#'] / stat_values['all_con_total'],\n",
    "                    '5P-PT_con': stat_values['all_5P-PT_con#'] / stat_values['all_con_total'],\n",
    "                    '5P-IT_con': stat_values['all_5P-IT_con#'] / stat_values['all_con_total'],\n",
    "                    '5P-NP_con': stat_values['all_5P-NP_con#'] / stat_values['all_con_total'],\n",
    "                    '6P_con': stat_values['all_6P_con#'] / stat_values['all_con_total'],\n",
    "                    'BC_con': stat_values['all_BC_con#'] / stat_values['all_con_total'],\n",
    "                    'MC_con': stat_values['all_MC_con#'] / stat_values['all_con_total'],\n",
    "                    'BPC_con': stat_values['all_BPC_con#'] / stat_values['all_syn_total'],\n",
    "                    'NGC_con': stat_values['all_NGC_con#'] / stat_values['all_con_total'],\n",
    "                    'Undetermined_subclass_con': stat_values['all_Undetermined_subclass_con#'] / stat_values['all_con_total'],\n",
    "                   \n",
    "    }\n",
    "    percentage.append(stat_percentage) \n",
    "    \n",
    "\n",
    "synapse_table_values = pd.DataFrame(values)\n",
    "synapse_table_percentage = pd.DataFrame(percentage)\n",
    "\n",
    "#total_values = pd.DataFrame(synapse_table_values.sum(), columns=parts.columns, index=[\"Total\"])\n",
    "#stats_type.append(stat)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
